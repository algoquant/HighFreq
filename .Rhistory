qqplot(tdata, returns, xlab="t-Dist Quantiles", ylab="VTI Quantiles",
main="Q-Q plot of VTI Returns vs Student’s t-distribution")
probs <- c(0.25, 0.75)
y <- quantile(returns, probs)
x <- quantile(tdata, probs)
slope <- diff(y)/diff(x)  ## observed slope between quantiles
int <- y[1L]-slope*x[1L]  ## intercept
abline(int, slope, lwd=2, col="red")   ## draw the line
rm(x, y)
?slope
?intercept
ks.test(returns, tdata)
ptdistr <- function(x, dfree, loc=0, scalev=1) {
pt((x-loc)/scalev, df=dfree)
}  # end ptdistr
ks.test(sample(returns, replace=TRUE), ptdistr, dfree=3, loc=loc, scalev=scalev)
ks.test(sample(returns, replace=TRUE), ptdistr, dfree=2, loc=loc, scalev=scalev)
par_init <- c(mean=0, scale=0.01)  # Initial parameters
optim_fit <- optim(par=par_init,
fn=likeli_hood, # Log-likelihood function
data=returns,
dfree=3, # Degrees of freedom
method="L-BFGS-B", # Quasi-Newton method
upper=c(1, 0.1), # Upper constraint
lower=c(-1, 1e-7)) # Lower constraint
# Optimal parameters
loc <- optim_fit$par["mean"]
scalev <- optim_fit$par["scale"]
loc; scalev
tdata <- scalev*rt(NROW(returns), df=3) + loc
qqplot(tdata, returns, xlab="t-Dist Quantiles", ylab="VTI Quantiles",
main="Q-Q plot of VTI Returns vs Student’s t-distribution")
probs <- c(0.25, 0.75)
qrets <- quantile(returns, probs)
qtdata <- quantile(tdata, probs)
slope <- diff(qrets)/diff(qtdata)
intercept <- qrets[1]-slope*qtdata[1]
abline(intercept, slope, lwd=2, col="red")
ks.test(returns, tdata)
ks.test(sample(returns, replace=TRUE), ptdistr, dfree=3, loc=loc, scalev=scalev)
madv <- mad(returns)
histp <- hist(returns, col="lightgrey",
xlab="returns", breaks=100, xlim=c(-5*madv, 5*madv),
ylab="frequency", freq=FALSE, main="Histogram of VTI Returns")
lines(density(returns, adjust=1.5), lwd=3, col="blue")
curve(expr=dnorm(x, mean=mean(returns),
sd=sd(returns)), add=TRUE, lwd=3, col="green")
tdistr <- function(x, dfree, loc=0, scalev=1) {
dt((x-loc)/scalev, df=dfree)/scalev
}  # end tdistr
curve(expr=tdistr(x, dfree=3, loc=loc, scalev=scalev), col="red", lwd=3, add=TRUE)
legend("topright", inset=0.05, bty="n",
leg=c("density", "t-distr", "normal"),
lwd=6, lty=1, col=c("blue", "red", "green"))
returns <- as.numeric(na.omit(rutils::etfenv$returns$VTI))[1:4999]
dig_its <- options(digits=5)
dig_its
shapiro.test(rnorm(NROW(returns)))
returns <- as.numeric(na.omit(rutils::etfenv$returns$VTI))[1:4999]
shapiro.test(as.numeric(returns))
shapiro.test(runif(NROW(returns)))
?counts
ls()
rm(list = ls())
load("/Users/jerzy/Develop/lecture_slides/data/sp500.RData")
prices <- eapply(sp500env, quantmod::Cl)
prices <- rutils::do_call(cbind, prices)
sum(is.na(prices))
prices <- zoo::na.locf(prices, na.rm=FALSE)
sum(is.na(prices))
colnamev <- rutils::get_name(colnames(prices))
colnames(prices) <- colnamev
returns <- xts::diff.xts(log(prices))
set.seed(1121)
samplev <- sample(NCOL(returns), s=100, replace=FALSE)
prices100 <- prices[, samplev]
returns100 <- returns[, samplev]
save(prices, prices100,
file="/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")
save(returns, returns100,
file="/Users/jerzy/Develop/lecture_slides/data/sp500_returns.RData")
?tickers
?param
?brackets
?aggs
?exponent
?base
getwd()
setwd("/Users/jerzy/Develop/lecture_slides")
getwd()
knitr::purl("/Users/jerzy/Develop/lecture_slides/FRE7241_Lecture_1.Rnw", documentation=0, quiet=TRUE)
ls()
rm(list = ls())
ls()
# Calculate cumulative sum of a vector
vectorv <- runif(1e5)
ls()
NROW(vectorv)
# Use compiled function
cumsumv <- cumsum(vectorv)
head(cumsumv)
tail(cumsumv)
tail(vectorv)
head(cumsumv)
head(vectorv)
cumsum
cumsumv2 <- vectorv
for (i in 2:NROW(vectorv))
cumsumv2[i] <- (vectorv[i] + cumsumv2[i-1])
all.equal(cumsumv, cumsumv2)
library(microbenchmark)
search()
all.equal(cumsumv, cumsumv2)
args(microbenchmark)
?microbenchmark
summary(microbenchmark(
cumsym=cumsum(vectorv),
loopsym={
cumsumv2 <- vectorv
for (i in 2:NROW(vectorv))
cumsumv2[i] <- (vectorv[i] + cumsumv2[i-1])
},
loop_nalloc={
# Doesn't allocate memory to cumsumv3
cumsumv3 <- vectorv[1]
for (i in 2:NROW(vectorv))
# This command adds an extra element to cumsumv3
cumsumv3[i] <- (vectorv[i] + cumsumv3[i-1])
},
times=10))[, c(1, 4, 5)]
5501.83/125.88
vecv <- numeric(11)
vecv
1:11
3*(1:11)
stdevs <- structure(1:3, namesv=paste0("sd=", 1:3))
me_ans <- structure(-1:1, namesv=paste0("mean=", -1:1))
stdevs
me_ans
rnorm(5)
?rnorm
sd(rnorm(1e3))
sd(rnorm(1e3))
mean(rnorm(1e3))
mean(rnorm(1e3))
mean(rnorm(1e3))
rnorm(5, sd=2)
sd(rnorm(1e3, sd=2))
sd(rnorm(1e3, sd=2))
sd(rnorm(1e3, sd=2))
sd(rnorm(1e3, sd=2))
?sapply
stdevs <- structure(1:3, names=paste0("sd=", 1:3))
me_ans <- structure(-1:1, names=paste0("mean=", -1:1))
stdevs
me_ans
rnorm(1, sd=stdevs)
rnorm(1, mean=me_ans)
sapply(stdevs, function(stdev) rnorm(n=2, sd=stdev))
sapply(stdevs, function(stdev) rnorm(n=5, sd=stdev))
foo <- sapply(stdevs, function(stdev) rnorm(n=1e3, sd=stdev))
dim(foo)
sapply(foo, sd)
apply(foo, 2, sd)
paws <- function(x, sleep_time=0.01) {
Sys.sleep(sleep_time)
x
}  # end paws
paws(11, 1)
paws(11, 2)
library(parallel)  # Load package parallel
numcores <- detectCores() - 1
numcores
paw_s <- mclapply(1:10, paws, mc.cores=numcores)
?mclapply
summary(microbenchmark(
standard = lapply(1:10, paws),
parallel = parLapply(cluster, 1:10, paws),
times=10)
)[, c(1, 4, 5)]
summary(microbenchmark(
standard = lapply(1:10, paws),
parallel = mclapply(1:10, paws),
times=10)
)[, c(1, 4, 5)]
summary(microbenchmark(
standard = lapply(1:100, paws),
parallel = mclapply(1:100, paws),
times=10)
)[, c(1, 4, 5)]
1085.09/583.69
iter_ations <- 3:13
compute_times <- sapply(iter_ations,
function(max_iterations) {
summary(microbenchmark(
standard = lapply(1:max_iterations, paws),
parallel = mclapply(1:max_iterations, paws),
times=10))[, 4]
})  # end sapply
compute_times
compute_times <- t(compute_times)
compute_times
colnames(compute_times) <- c("standard", "parallel")
compute_times
rownames(compute_times) <- iter_ations
compute_times
dev.new(width=6, height=5, noRStudioGD=TRUE)
plot(x=rownames(compute_times),
y=compute_times[, "standard"],
type="l", lwd=2, col="blue",
main="Compute times",
xlab="number of iterations in loop", ylab="",
ylim=c(0, max(compute_times[, "standard"])))
lines(x=rownames(compute_times),
lines(x=rownames(compute_times),
y=compute_times[, "parallel"], lwd=2, col="green")
)
plot(x=rownames(compute_times),
y=compute_times[, "standard"],
type="l", lwd=2, col="blue",
main="Compute times",
xlab="number of iterations in loop", ylab="",
ylim=c(0, max(compute_times[, "standard"])))
lines(x=rownames(compute_times),
y=compute_times[, "parallel"], lwd=2, col="green")
legend(x="topleft", legend=colnames(compute_times),
inset=0.1, cex=1.0, bg="white",
lwd=2, lty=1, col=c("blue", "green"))
rm(list = ls())
set.seed(1121)  # Reset random number generator
barp <- 20  # Barrier level
nrows <- 1000  # Number of simulation steps
paths <- numeric(nrows)  # Allocate path vector
paths[1] <- 0  # Initialize path
indeks <- 2  # Initialize simulation index
indeks
while ((indeks <= nrows) && (paths[indeks - 1] < barp)) {
# Simulate next step
paths[indeks] <- paths[indeks - 1] + rnorm(1)
indeks <- indeks + 1  # Advance indeks
}  # end while
head(paths)
tail(paths)
indeks
paths[indeks - 1]
paths[indeks - 2]
indeks <= nrows
paths[indeks - 1]
indeks*nrows
if (indeks <= nrows)
paths[indeks:nrows] <- paths[indeks - 1]
plot(paths, type="l", col="black",
lty="solid", lwd=2, xlab="", ylab="")
abline(h=barp, lwd=3, col="red")
title(main="Brownian Motion Crossing a Barrier Level", line=0.5)
set.seed(1121)  # Reset random number generator
paths <- cumsum(rnorm(nrows))
plot(paths, type="l", col="black",
lty="solid", lwd=2, xlab="", ylab="")
crossp <- which(paths > barp)
crossp
NROW(crossp)
if (NROW(crossp)>0) {
paths[(crossp[1]+1)/nrows] <- paths[crossp[1]]
}  # end if
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 1, 1))
plot(paths, type="l", col="black",
lty="solid", lwd=2, xlab="", ylab="")
abline(h=barp, lwd=3, col="red")
title(main="Brownian Motion Crossing a Barrier Level", line=0.5)
paths[(crossp[1]+1)/nrows] <- paths[crossp[1]]
plot(paths, type="l", col="black",
lty="solid", lwd=2, xlab="", ylab="")
abline(h=barp, lwd=3, col="red")
title(main="Brownian Motion Crossing a Barrier Level", line=0.5)
paths[(crossp[1]+1):nrows] <- paths[crossp[1]]
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 1, 1))
plot(paths, type="l", col="black",
lty="solid", lwd=2, xlab="", ylab="")
abline(h=barp, lwd=3, col="red")
title(main="Brownian Motion Crossing a Barrier Level", line=0.5)
rm(list = ls())
sigmav <- 1.0  # Volatility
drift <- 0.0  # Drift
nrows <- 1000  # Number of simulation steps
nsimu <- 100  # Number of simulations
set.seed(1121)
nsimu*nrows
paths <- rnorm(nsimu*nrows, mean=drift, sd=sigmav)
paths <- matrix(paths, nc=nsimu)
dim(paths)
head(paths[, 1:6])
head(paths[, 1:6], 11)
paths <- matrixStats::colCumsums(paths)
head(paths[, 1:6], 11)
foo <- rowMeans(paths)
plot(foo, t="l")
foo <- matrixStats::rowSds(paths)
plot(foo, t="l")
sqrt(1e3)
mean(paths[nrows, ]) ; sd(paths[nrows, ])
strikep
strikep <- 50  # Strike price
strikep
paths[nrows, ]
payouts <- (paths[nrows, ] - strikep)
payouts
payouts[payouts > 0]
sum(payouts[payouts > 0])/nsimu
objfun <- function(input, param1=0.01) {
sin(0.25*pi*input) + param1*(input-1)^2
}  # end objfun
curve(expr=objfun, type="l", xlim=c(-8, 9),
xlab="", ylab="", lwd=2)
title(main="Objective Function", line=-1)
unlist(optimize(f=objfun, interval=c(-4, 2)))
unlist(optimize(f=objfun, interval=c(0, 8)))
optimize(f=objfun, interval=c(0, 8))
rastrigin <- function(x, y, param=25) {
x^2 + y^2 - param*(cos(x) + cos(y))
}  # end rastrigin
rastrigin(c(-10, 5), c(-10, 5))
rastrigin(5, 5)
rastrigin(c(-10, 5), 5)
rastrigin(c(-10, 5), c(5, 5))
library(rgl)
rgl::persp3d(x=rastrigin, xlim=c(-10, 10), ylim=c(-10, 10),
col="green", axes=FALSE, param=15)
rgl::rglwidget(elementId="plot3drgl", width=400, height=400)
rastrigin <- function(vectorv, param=25) {
sum(vectorv^2 - param*cos(vectorv))
}  # end rastrigin
vectorv <- c(pi/6, pi/6)
rastrigin(vectorv=vectorv)
vectorv <- c(-pi/6, pi/6)
rastrigin(vectorv=vectorv)
vectorv <- c(-pi, pi/6)
rastrigin(vectorv=vectorv)
vectorv <- c(-pi, pi)
rastrigin(vectorv=vectorv)
?optim
c(4*pi, 4*pi)
(pi/2, pi/2)
(pi/2, pi/2)
c(pi/2, pi/2)
vectorv
vectorv <- c(pi/6, pi/6)
vectorv
rastrigin
optimd <- optim(par=vectorv, fn=rastrigin,
method="L-BFGS-B",
upper=c(4*pi, 4*pi),
lower=c(pi/2, pi/2),
param=1)
optimd
optimd$par
optimd$value
rastrigin(optimd$par, param=1)
rastrigin <- function(vectorv, param=25) {
sum(vectorv^2 - param*cos(vectorv))
}  # end rastrigin
library(DEoptim)
optimd <-  DEoptim(rastrigin,
upper=c(6, 6), lower=c(-6, -6),
DEoptim.control(trace=FALSE, itermax=50))
optimd$optim$bestmem
optimd <-  DEoptim(rastrigin,
upper=c(6, 6), lower=c(1, 1),
DEoptim.control(trace=FALSE, itermax=50))
optimd$optim$bestmem
optimd <-  DEoptim(rastrigin,
upper=c(6, 6), lower=c(2, 2),
DEoptim.control(trace=FALSE, itermax=50))
optimd$optim$bestmem
rm(list = ls())
ls()
load("/Users/jerzy/Develop/lecture_slides/data/sp500.RData")
ls()
ls(sp500env)
head(sp500env$AAPL)
head(sp500env$TSLA)
NROW(sp500env)
closep <- quantmod::Cl(sp500env$TSLA)
head(closep)
prices <- eapply(sp500env, quantmod::Cl)
class(prices)
head(prices$TSLA)
?do.call
foo <- list(1, 2, 3, 4)
foo
sum(foo)
sum(1, 2, 3, 4)
sum(foo[[1]], foo[[2]], foo[[3]], foo[[4]])
do.call(sum, foo)
prices <- rutils::do_call(cbind, prices)
class(prices)
dim(prices)
head(prices[, 1:5], 7)
foo <- c(1, 2, NA, 4)
foo
zoo::na.locf(foo)
prices <- zoo::na.locf(prices, na.rm=FALSE)
rutils::get_name("DXC.Close")
rutils::get_name("DXC.Closeeeee")
rutils::get_name("DXoC.Closeeeee")
rutils::get_name
colnames(prices) <- rutils::get_name(colnames(prices))
head(prices[, 1:5], 7)
returns <- xts::diff.xts(prices)/
rutils::lagit(prices, pad_zeros=FALSE)
head(returns[, 1:5], 7)
foo <- is.na(prices)
head(foo[, 1:5], 7)
datav <- rowSums(is.na(prices))
head(datav)
tail(datav)
class(datav)
foo <- index(prices)
head(foo)
datav <- xts::xts(datav, order.by=index(prices))
class(datav)
dygraphs::dygraph(datav, main="Number of S&P500 Constituents Without Prices") %>%
dyOptions(colors="blue", strokeWidth=2) %>%
dyAxis("y", valueRange=c(0, 300))
dygraphs::dygraph(datav, main="Number of S&P500 Constituents Without Prices") %>%
dyOptions(colors="blue", strokeWidth=2)
dygraphs::dygraph(datav, main="Number of S&P500 Constituents Without Prices") %>%
dyOptions(colors="blue", strokeWidth=2) %>%
dyAxis("y", valueRange=c(0, 600))
?means
?cluster
ls()
head(foo)
foo <- as.Date(foo)
head(foo)
head(sp500env$AAPL)
foo <- index(sp500env$AAPL)
head(foo)
class(sp500env$AAPL)
class(index(sp500env$AAPL))
for (symbol in ls(sp500env)) {
xtes <- get(symbol, envir=sp500env)
index(xtes) <- as.Date(index(xtes))
assign(symbol, xtes, envir=sp500env)
}  # end for
class(index(sp500env$AAPL))
foo <- index(sp500env$AAPL)
head(foo)
prices <- eapply(sp500env, quantmod::Cl)
prices <- rutils::do_call(cbind, prices)
prices <- zoo::na.locf(prices, na.rm=FALSE)
colnamev <- rutils::get_name(colnames(prices))
colnames(prices) <- colnamev
returns <- xts::diff.xts(log(prices))
set.seed(1121)
samplev <- sample(NCOL(returns), s=100, replace=FALSE)
prices100 <- prices[, samplev]
returns100 <- returns[, samplev]
head(returns100[, 1:5])
head(prices[, 1:5])
save(prices, prices100,
file="/Users/jerzy/Develop/lecture_slides/data/sp500_prices.RData")
save(returns, returns100,
file="/Users/jerzy/Develop/lecture_slides/data/sp500_returns.RData")
getwd()
knitr::purl("/Users/jerzy/Develop/lecture_slides/FRE7241_Lecture_1.Rnw", documentation=0, quiet=TRUE)
library(HighFreq)
Rcpp::sourceCpp("/Users/jerzy/Develop/Rcpp/rcpp_hello_world.cpp")
ls()
rcpp_hellowporld()
rm(rcpp_hellowporld())
rm(rcpp_hellowporld)
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
hellowporld()
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
hellowporld()
ohlc <- log(rutils::etfenv$VTI)
closep <- quantmod::Cl(ohlc)
colnames(closep) <- "VTI"
nrows <- NROW(closep)
lambda <- 0.9
ewmap <- HighFreq::run_mean(closep, lambda=lambda)
prices <- cbind(closep, ewmap)
colnames(prices) <- c("VTI", "VTI EWMA")
colnamev <- colnames(prices)
dygraphs::dygraph(prices["2009"], main="Recursive VTI EWMA Prices") %>%
dySeries(name=colnamev[1], label=colnamev[1], strokeWidth=1, col="blue") %>%
dySeries(name=colnamev[2], label=colnamev[2], strokeWidth=2, col="red") %>%
dyLegend(show="always", width=500)
dev.new(width=6, height=5, noRStudioGD=TRUE)
dygraphs::dygraph(prices["2009"], main="Recursive VTI EWMA Prices") %>%
dySeries(name=colnamev[1], label=colnamev[1], strokeWidth=1, col="blue") %>%
dySeries(name=colnamev[2], label=colnamev[2], strokeWidth=2, col="red") %>%
dyLegend(show="always", width=500)
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
library(HighFreq)
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
library(HighFreq)
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
library(HighFreq)
q()
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
ls()
hello()
library(HighFreq)
q()
Rcpp::sourceCpp("/Users/jerzy/Develop/lecture_slides/scripts/hello_world.cpp")
library(HighFreq)
library(HighFreq)
library(HighFreq)
R.home()
.libPaths()
