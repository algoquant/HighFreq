% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{run_reg}
\alias{run_reg}
\title{Calculate recursively the trailing regressions of streaming \emph{time
series} of response and predictor data, and calculate the residuals, alphas,
and betas.}
\usage{
run_reg(respv, predv, lambda, method = "none")
}
\arguments{
\item{\code{respv}}{A single-column \emph{time series} or a single-column
\emph{matrix} of response data.}

\item{\code{predv}}{A \emph{time series} or a \emph{matrix} of predictor
data.}

\item{\code{lambda}}{A decay factor which multiplies past
estimates.}

\item{\code{method}}{A \emph{character string} specifying the method for
scaling the residuals (the default is \code{method = "none"} - no
scaling).}
}
\value{
A \emph{matrix} with the regression residuals, alphas, and betas,
  with the same number of rows as the input argument \code{predv}.
}
\description{
Calculate recursively the trailing regressions of streaming \emph{time
series} of response and predictor data, and calculate the residuals, alphas,
and betas.
}
\details{
The function \code{run_reg()} calculates the vectors of \emph{alphas}
  \eqn{\alpha_t}, \emph{betas} \eqn{\beta_t}, and the \emph{residuals}
  \eqn{\epsilon_t} of trailing regressions, by recursively weighting the
  current estimates with past estimates, using the decay factor \eqn{\lambda}:
  \deqn{
    \bar{r}_t = \lambda \bar{r}_{t-1} + (1-\lambda) r_t
  }
  \deqn{
    \bar{p}_t = \lambda \bar{p}_{t-1} + (1-\lambda) p_t
  }
  \deqn{
    \sigma^2_t = \lambda \sigma^2_{t-1} + (1-\lambda) p^T_t p_t
  }
  \deqn{
    cov_t = \lambda cov_{t-1} + (1-\lambda) r^T_t p_t
  }
  \deqn{
    \beta_t = \lambda \beta_{t-1} + (1-\lambda) \sigma^{-2}_t cov_t
  }
  \deqn{
    \alpha_t = \bar{r}_t - \beta_t \bar{p}_t
  }
  \deqn{
    \epsilon_t = \lambda \epsilon_{t-1} + (1-\lambda) (r_t - \beta_t p_t)
  }
  \deqn{
    \varsigma^2_t = \lambda \varsigma^2_{t-1} + (1-\lambda) \epsilon^2_t
  }
  Where \eqn{r_t} and \eqn{p_t} are the response and predictor data,
  \eqn{cov_t} is the covariance matrix between the response and the
  predictor data,
  \eqn{\sigma^2_t} is the covariance matrix of the predictors (\eqn{\sigma^{-2}_t}
  is the inverse of the covariance), and \eqn{\varsigma^2_t} is the
  residual variance.

  The matrices \eqn{\sigma^2}, \eqn{cov}, \eqn{\alpha}, and
  \eqn{\beta} have the same number of rows as the input argument
  \code{predv}.

  The function \code{run_reg()} calculates the regressions with an intercept
  (constant) term. The vector of \emph{alphas} \eqn{\alpha_t} is the
  intercept value.

  The above recursive formulas are equivalent to a convolution with
  exponentially decaying weights, but they're much faster to calculate.
  The recursive formulas are convenient for processing live streaming data
  because they don't require maintaining a buffer of past data.
  Using exponentially decaying weights is more natural than using a sliding
  look-back interval, because it gradually "forgets" about the past data.

  The value of the decay factor \eqn{\lambda} must be in the range between
  \code{0} and \code{1}.
  If \eqn{\lambda} is close to \code{1} then the decay is weak and past
  values have a greater weight, so the trailing values have a greater
  dependence on past data.  This is equivalent to a long look-back
  interval.
  If \eqn{\lambda} is much less than \code{1} then the decay is strong and
  past values have a smaller weight, so the trailing values have a weaker
  dependence on past data.  This is equivalent to a short look-back
  interval.

  The \emph{residuals} may be scaled by their volatilities to obtain the
  \emph{z-scores}. The default is \code{method = "none"} - no scaling.
  If the argument \code{method = "scale"} then the \emph{residuals}
  \eqn{\epsilon_t} are divided by their volatilities \eqn{\varsigma_t}
  without subtracting their means:
  \deqn{
    \epsilon_t = \frac{\epsilon_t}{\varsigma_t}
  }
  If the argument \code{method = "standardize"} then the residual means
  \eqn{\bar{\epsilon}} are subtracted from the \emph{residuals}, and then
  they are divided by their volatilities \eqn{\varsigma_t}:
  \deqn{
    \epsilon_t = \frac{\epsilon_t - \bar{\epsilon}}{\varsigma_t}
  }
  Which are equal to the \emph{z-scores}.

  The function \code{run_reg()} returns multiple columns of data, with the
  same number of rows as the input argument \code{predv}. If the matrix
  \code{predv} has \code{n} columns then \code{run_reg()} returns a
  matrix with \code{n+2} columns.  The first column contains the
  \emph{residuals}, the second the \emph{alphas}, and the remaining columns
  contain the \emph{betas}.
}
\examples{
\dontrun{
# Calculate historical returns
retsp <- na.omit(rutils::etfenv$returns[, c("XLF", "VTI", "IEF")])
# Response equals XLF returns
respv <- retsp[, 1]
# Predictor matrix equals VTI and IEF returns
predv <- retsp[, -1]
# Calculate the trailing regressions
lambda <- 0.9
regs <- HighFreq::run_reg(respv=respv, predv=predv, lambda=lambda)
# Plot the trailing residuals
datav <- cbind(cumsum(respv), regs[, 1])
colnames(datav) <- c("XLF", "residuals")
colnamev <- colnames(datav)
dygraphs::dygraph(datav, main="Residuals of XLF Versus VTI and IEF") \%>\%
  dyAxis("y", label=colnamev[1], independentTicks=TRUE) \%>\%
  dyAxis("y2", label=colnamev[2], independentTicks=TRUE) \%>\%
  dySeries(name=colnamev[1], axis="y", label=colnamev[1], strokeWidth=2, col="blue") \%>\%
  dySeries(name=colnamev[2], axis="y2", label=colnamev[2], strokeWidth=2, col="red")
}

}
