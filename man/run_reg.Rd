% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{run_reg}
\alias{run_reg}
\title{Perform regressions on the streaming \emph{time series} of response and
predictor data, and calculate the regression coefficients, the residuals,
and the forecasts, using online recursive formulas.}
\usage{
run_reg(respv, predm, lambdaf, controll)
}
\arguments{
\item{\code{respv}}{A single-column \emph{time series} or a single-column
\emph{matrix} of response data.}

\item{\code{predm}}{A \emph{time series} or a \emph{matrix} of predictor
data.}

\item{\code{lambdaf}}{A decay factor which multiplies past estimates.}

\item{\code{controll}}{A \emph{list} of model parameters (see Details).}
}
\value{
A \emph{matrix} with the regression coefficients, the residuals, and
  the forecasts (in that order - see details), with the same number of rows
  as the predictor argument \code{predm}.
}
\description{
Perform regressions on the streaming \emph{time series} of response and
predictor data, and calculate the regression coefficients, the residuals,
and the forecasts, using online recursive formulas.
}
\details{
The function \code{run_reg()} performs regressions on the streaming \emph{time
  series} of response \eqn{r_t} and predictor \eqn{p_t} data:
  \deqn{
    r_t = \beta_t p_t + \epsilon_t
  }
  Where \eqn{\beta_t} are the trailing regression coefficients and
  \eqn{\epsilon_t} are the residuals.
  
  It recursively updates the covariance matrix \eqn{{cov}_t} between the
  response and the predictor data, and the covariance matrix
  \eqn{{cov}_{pt}} between the predictors, using the decay factor
  \eqn{\lambda}:
  \deqn{
    {cov}_t = \lambda {cov}_{t-1} + (1 - \lambda) r^T_t p_t
  }
  \deqn{
    {cov}_{p t} = \lambda {cov}_{p (t-1)} + (1 - \lambda) p^T_t p_t
  }
  
  It calculates the regression coefficients \eqn{\beta_t} as equal to the
  covariance matrix between the response and the predictor data
  \eqn{{cov}_t}, divided by the covariance matrix between the predictors
  \eqn{{cov}_{pt}}:
  \deqn{
    \beta_t = {cov}_t \, {cov}^{-1}_{p t}
  }
  
  It calculates the residuals \eqn{\epsilon_t} as the difference between the
  response \eqn{r_t} minus the fitted values \eqn{\beta_t p_t}:
  \deqn{
    \epsilon_t = r_t - \beta_t p_t
  }
  
  And the residual variance \eqn{\sigma^2_t} as:
  \deqn{
    \bar{\epsilon}_t = \lambda \bar{\epsilon}_{t-1} + (1 - \lambda) \epsilon_t
  }
  \deqn{
    \sigma^2_t = \lambda^2 \sigma^2_{t-1} + (1 - \lambda^2) (\epsilon_t - \bar{\epsilon}_t)^2
  }

  Note that the variance decays as the square of \eqn{\lambda}, while the
  mean residuals decay as \eqn{\lambda}.
  This is because the variance is proportional to the square of the residuals.
  
  It then calculates the regression forecasts \eqn{f_t}, as equal to the
  past regression coefficients \eqn{\beta_{t-1}} times the current predictor
  data \eqn{p_t}:
  \deqn{
    f_t = \beta_{t-1} p_t
  }

  It finally calculates the forecast errors as the difference between the
  response minus the regression forecasts: \eqn{r_t - f_t}.

  The coefficient matrix \eqn{\beta} and the residuals \eqn{\epsilon} have
  the same number of rows as the predictor argument \code{predm}.

  The function \code{run_reg()} accepts a list of regression model
  parameters through the argument \code{controll}.
  The argument \code{controll} contains the parameters \code{regmod} and
  \code{residscale}.
  Below is a description of how these parameters work.
  The list of model parameters can be created using the function
  \code{param_reg()}.  

  The number of regression coefficients is equal to the number of columns of
  the predictor matrix \code{n}.
  If the predictor matrix contains a unit intercept column then the first
  regression coefficient is equal to the alpha value \eqn{\alpha}.

  If \code{regmod = "least_squares"} (the default) then it performs the
  standard least squares regression.  This is currently the only option.

  The \emph{residuals} and the the \emph{forecast errors} may be scaled by
  their volatilities to obtain the \emph{z-scores}. 
  The default is \code{residscale = "none"} - no scaling.
  If the argument \code{residscale = "scale"} then the \emph{residuals}
  \eqn{\epsilon_t} are divided by their volatilities \eqn{\sigma_t}
  without subtracting their means:
  \deqn{
    \epsilon_t = \frac{\epsilon_t}{\sigma_t}
  }
  If the argument \code{residscale = "standardize"} then the residual means
  \eqn{\bar{\epsilon}} are subtracted from the \emph{residuals}, and then
  they are divided by their volatilities \eqn{\sigma_t}:
  \deqn{
    \epsilon_t = \frac{\epsilon_t - \bar{\epsilon}}{\sigma_t}
  }
  Which are equal to the \emph{z-scores}.
  
  The \emph{forecast errors} are also scaled in the same way as the
  \emph{residuals}, according to the argument\code{residscale}.

  The above online recursive formulas are convenient for processing live
  streaming data because they don't require maintaining a buffer of past
  data.
  The above recursive formulas are equivalent to a convolution with
  exponentially decaying weights, but they're much faster to calculate.
  Using exponentially decaying weights is more natural than using a sliding
  look-back interval, because it gradually "forgets" about the past data.

  The value of the decay factor \eqn{\lambda} must be in the range between
  \code{0} and \code{1}.
  If \eqn{\lambda} is close to \code{1} then the decay is weak and past
  values have a greater weight, so the trailing values have a greater
  dependence on past data.  This is equivalent to a long look-back
  interval.
  If \eqn{\lambda} is much less than \code{1} then the decay is strong and
  past values have a smaller weight, so the trailing values have a weaker
  dependence on past data.  This is equivalent to a short look-back
  interval.

  The function \code{run_reg()} returns multiple columns of data, with the
  same number of rows as the predictor matrix \code{predm}. If the predictor
  matrix \code{predm} has \code{n} columns then \code{run_reg()} returns a
  matrix with \code{n+2} columns.
  The first \code{n} columns contain the regression coefficients (with the
  first column equal to the alpha value \eqn{\alpha}).
  The last \code{2} columns are the regression residuals and the forecast
  errors.
}
\examples{
\dontrun{
# Calculate historical returns
retp <- na.omit(rutils::etfenv$returns[, c("XLF", "VTI", "IEF")])
# Response equals XLF returns
respv <- retp[, 1]
# Predictor matrix equals VTI and IEF returns
predm <- retp[, -1]
# Add unit intercept column to the predictor matrix
predm <- cbind(rep(1, NROW(predm)), predm)
# Calculate the trailing regressions
lambdaf <- 0.9 # Decay factor
# Create a list of regression parameters
controll <- HighFreq::param_reg(residscale="standardize")
regs <- HighFreq::run_reg(respv=respv, predm=predm, lambdaf=lambdaf, controll=controll)
# Plot the trailing residuals
datav <- cbind(cumsum(respv), regs[, NCOL(regs)])
colnames(datav) <- c("XLF", "residuals")
colnamev <- colnames(datav)
dygraphs::dygraph(datav["2008/2009"], main="Residuals of XLF Versus VTI and IEF") \%>\%
  dyAxis("y", label=colnamev[1], independentTicks=TRUE) \%>\%
  dyAxis("y2", label=colnamev[2], independentTicks=TRUE) \%>\%
  dySeries(axis="y", strokeWidth=2, col="blue") \%>\%
  dySeries(axis="y2", strokeWidth=2, col="red") \%>\%
  dyLegend(show="always", width=300)

# Calculate the trailing regressions using R code
lambda1 <- (1-lambdaf)
respv <- zoo::coredata(respv)
predm <- zoo::coredata(predm)
nrows <- NROW(predm)
ncols <- NCOL(predm)
covrespred <- respv[1, ]*predm[1, ]
covpred <- outer(predm[1, ], predm[1, ])
betas <- matrix(numeric(nrows*ncols), nc=ncols)
betas[1, ] <- covrespred \%*\% MASS::ginv(covpred)
resids <- numeric(nrows)
residm <- 0
residv <- 0
for (it in 2:nrows) {
 covrespred <- lambdaf*covrespred + lambda1*respv[it, ]*predm[it, ]
 covpred <- lambdaf*covpred + lambda1*outer(predm[it, ], predm[it, ])
 betas[it, ] <- covrespred \%*\% MASS::ginv(covpred)
 resids[it] <- respv[it, ] - (betas[it, ] \%*\% predm[it, ])
 residm <- lambdaf*residm + lambda1*resids[it]
 residv <- lambdaf*residv + lambda1*(resids[it] - residm)^2
 resids[it] <- (resids[it] - residm)/sqrt(residv)
} # end for
# Compare values, excluding warmup period
all.equal(regs[-(1:1e3), ], cbind(betas, resids)[-(1:1e3), ], check.attributes=FALSE)
 
}

}
