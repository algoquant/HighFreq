% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{run_scale}
\alias{run_scale}
\title{Standardize (center and scale) the columns of a \emph{time series} of data
over time and in place, without copying the data in memory, using
\code{RcppArmadillo}.}
\usage{
run_scale(tseries, lambda, center = TRUE, scale = TRUE)
}
\arguments{
\item{\code{tseries}}{A \emph{time series} or \emph{matrix} of data.}

\item{\code{lambda}}{A decay factor which multiplies past estimates.}

\item{\code{center}}{A \emph{Boolean} argument: if \code{TRUE} then center
the columns so that they have zero mean or median (the default is
\code{TRUE}).}

\item{\code{scale}}{A \emph{Boolean} argument: if \code{TRUE} then scale the
columns so that they have unit standard deviation or MAD (the default is
\code{TRUE}).}
}
\value{
Void (no return value - modifies the data in place).
}
\description{
Standardize (center and scale) the columns of a \emph{time series} of data
over time and in place, without copying the data in memory, using
\code{RcppArmadillo}.
}
\details{
The function \code{run_scale()} performs a trailing standardization
  (centering and scaling) of the columns of the \code{tseries} argument
  using \code{RcppArmadillo}.

  The function \code{run_scale()} accepts a \emph{pointer} to the argument
  \code{tseries}, and it overwrites the old data with the standardized
  data. It performs the calculation in place, without copying the data in
  memory, which can significantly increase the computation speed for large
  time series.

  The function \code{run_scale()} performs a loop over the rows of
  \code{tseries}, and standardizes the data using its trailing means and
  standard deviations.

  The function \code{run_scale()} calculates the trailing mean and variance
  of streaming \emph{time series} data \eqn{r_t}, by recursively weighting
  the past estimates with the new data, using the decay factor \eqn{\lambda}:
  \deqn{
    \bar{r}_t = \lambda \bar{r}_{t-1} + (1-\lambda) r_t
  }
  \deqn{
    \sigma^2_t = \lambda \sigma^2_{t-1} + (1-\lambda) (r_t - \bar{r}_t)^2
  }
  Where \eqn{\bar{r}_t} is the trailing mean and \eqn{\sigma^2_t} is the
  trailing variance.
  
  It then calculates the standardized data as follows:
  \deqn{
    r^{\prime}_t = \frac{r_t - \bar{r}_t}{\sigma_t}
  }

  If the arguments \code{center} and \code{scale} are both \code{TRUE} (the
  defaults), then \code{calc_scale()} standardizes the data.
  If the argument \code{center} is \code{FALSE} then \code{calc_scale()}
  only scales the data (divides it by the standard deviations).
  If the argument \code{scale} is \code{FALSE} then \code{calc_scale()}
  only demeans the data (subtracts the means).
  
  The value of the decay factor \eqn{\lambda} must be in the range between
  \code{0} and \code{1}.  
  If \eqn{\lambda} is close to \code{1} then the decay is weak and past
  values have a greater weight, and the trailing variance values have a
  stronger dependence on past data.  This is equivalent to a long
  look-back interval.
  If \eqn{\lambda} is much less than \code{1} then the decay is strong and
  past values have a smaller weight, and the trailing variance values have a
  weaker dependence on past data.  This is equivalent to a short look-back
  interval.

  The above online recursive formulas are convenient for processing live
  streaming data because they don't require maintaining a buffer of past
  data.
  The formulas are equivalent to a convolution with exponentially decaying
  weights, but they're much faster to calculate.
  Using exponentially decaying weights is more natural than using a sliding
  look-back interval, because it gradually "forgets" about the past data.

  The function \code{run_scale()} uses \code{RcppArmadillo} \code{C++} code,
  so it can be over \code{100} times faster than the equivalent \code{R}
  code.
}
\examples{
\dontrun{
# Calculate historical returns
retp <- na.omit(rutils::etfenv$returns[, c("XLF", "VTI")])
# Calculate the trailing standardized returns using R code
lambdaf <- 0.9
lambda1 <- 1 - lambdaf
scaled <- zoo::coredata(retp)
meanm <- scaled[1, ];
vars <- scaled[1, ]^2;
for (it in 2:NROW(retp)) {
  meanm <- lambdaf*meanm + lambda1*scaled[it, ];
  vars <- lambdaf*vars + lambda1*(scaled[it, ] - meanm)^2;
  scaled[it, ] <- (scaled[it, ] - meanm)/sqrt(vars)
}  # end for
# Calculate the trailing standardized returns using C++ code
HighFreq::run_scale(retp, lambda=lambdaf)
all.equal(zoo::coredata(retp), scaled, check.attributes=FALSE)
# Compare the speed of RcppArmadillo with R code
library(microbenchmark)
summary(microbenchmark(
  Rcpp=HighFreq::run_scale(retp, lambda=lambdaf),
  Rcode={for (it in 2:NROW(retp)) {
   meanm <- lambdaf*meanm + lambda1*scaled[it, ];
   vars <- lambdaf*vars + lambda1*(scaled[it, ] - meanm)^2;
   scaled[it, ] <- (scaled[it, ] - meanm)/sqrt(vars)
  }},  # end for
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
}

}
