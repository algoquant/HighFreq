############
### ToDo list for package HighFreq: high frequency data scrubbing

### scripts for package building

## Steps for installing package called my_package, containing Rcpp code:
1. Create empty package directory with Rcpp::Rcpp.package.skeleton()
2. In the R directory create a file called my_package.R and add the header:

#' @useDynLib my_package
#' @importFrom Rcpp evalCpp
#' @exportPattern "^[[:alpha:]]+"
NULL

Add your R functions below the header.

3. Clean and rebuild (in Build menu)


## Build scripts:

# Install package from source on local drive
install.packages(pkgs="C:/Develop/R/HighFreq", repos=NULL, type="source")
# Install package from source on local drive using R CMD
R CMD INSTALL C:\Develop\R\HighFreq
# Install package from github
devtools::install_github(repo="algoquant/HighFreq", force=TRUE)
# build vignette package reference manual from *.Rd files
system("R CMD Rd2pdf C:/Develop/R/HighFreq")
cd C:\Develop\R\HighFreq\vignettes
R CMD Rd2pdf C:\Develop\R\HighFreq\



### comments

# volume weighted volatility is higher than simple average volatility because volumes are higher when volatility is higher. 

# The yang_zhang method has the lowest standard error assuming normal distribution, but not necessarily for fat-tailed distributions.
In addition, the yang_zhang method has lower bias caused by finite sampling.
The rogers_satchell method has the biggest bias caused by finite sampling and opening price jumps, and seriously underestimates the variance.

# Theoretically, the Yang-Zhang (YZ) and Garman-Klass-Yang-Zhang (GKYZ) range variance estimators are unbiased and have up to seven times smaller standard errors than the standard close-to-close estimator.  But in practice, prices are not observed continuously, so the price range is underestimated, and so is the variance when using the YZ and GKYZ range estimators.  Therefore in practice the YZ and GKYZ range estimators are biased (underestimate volatility).  In addition, the standard errors are reduced less than by the theoretical amount, for the same reason. 

# Using the average of open and close prices in the standard variance estimator (instead of just the close prices) doesn't reduce the standard error.

# High frequency data has three tenor horizons: daily (daily or lower frequency of data), intraday (secondly to daily frequency of data), and sub-second tenor horizons (sub-secondly or higher frequency of data).
At the sub-second tenor horizon, returns are dominated by noise and the bid-ask bounce.
Returns are dominated in their scale by the volatility, and they have no discernable trend.
At the sub-second horizon technical indicators are meaningless, and instead traders analyze the order book for clues about future returns.
At the intraday tenor horizon volatility, skew, and kurtosis are high, and mean-reversion dominates trending.
Technical indicators based on past returns and trading volumes can offer clues about future returns.
At the daily tenor horizon skew and kurtosis are small, and trending dominates mean-reversion.

# Calculating returns on 1-second bars doesn't make sense for two reasons: 
First, because the changes in price are very small, comparable to the precision of prices (number of significant digits).
As a result, price changes on 1-second bars are either zero or low multiples of the precision. 
Second, the 1-second bar prices bounce randomly between static bid and ask prices (the bid-ask bounce).  
Therefore 1-second bar returns carry almost no information.


### tasks to-do

+ [ ] Add function na_locf()
// [[Rcpp::export]]
NumericVector na_locf(NumericVector x)
{
  NumericVector output = Rcpp::clone(x);

  double lastNonNA = NA_REAL;
  int n = x.size();

  for (int i = 0; i < n; ++i)
  {
    double value = output[i];
    if (!ISNAN(value))
      lastNonNA = value;
    else
      output[i] = lastNonNA;
  }
  return output;
}
arma::uvec any_na_x(const NumericMatrix& x) {
  
  int n_rows_x = x.nrow();
  int n_cols_x = x.ncol();
  arma::uvec result(n_rows_x);
  
  for (int i = 0; i < n_rows_x; i++) {
    
    int any_na = 0;
    int j = 0;
    
    while ((any_na == 0) && (j < n_cols_x)) {
      if (std::isnan(x(i, j))) {
        any_na = 1;
      }
      j += 1;
    }
    
    result[i] = any_na;
    
  }
  
  return result;
  
}

arma::uvec any_na_xy(const NumericMatrix& x, const NumericMatrix& y) {
  
  int n_rows_xy = x.nrow();
  int n_cols_x = x.ncol();
  int n_cols_y = y.ncol();
  arma::uvec result(n_rows_xy);
  
  for (int i = 0; i < n_rows_xy; i++) {
    
    int any_na = 0;
    int j = 0;
    int k = 0;
    while ((any_na == 0) && (j < n_cols_x)) {
      if (std::isnan(x(i, j))) {
        any_na = 1;
      }
      j += 1;
    }
    while ((any_na == 0) && (k < n_cols_y)) {
      if (std::isnan(y(i, k))) {
        any_na = 1;
      }
      k += 1;
    }
    result[i] = any_na;
  }
  return result;
}



+ [ ] Add MAD, rank regression and rolling MAD and rank regression

+ [ ] Add to back_test() the simulation with limit orders

+ [ ] Update the description of roll_var()

+ [ ] Pass model parameters into back_test() as a vector or a list

+ [ ] Remove all parallel code and references to parallel packages from HighFreq

+ [ ] Create function for rolling Hampel filter using RcppArmadillo

+ [ ] Create function roll_median() for rolling median using RcppArmadillo

+ [ ] Create function predict_lm() which calculates the predicted out-of-sample values based on the coefficients from calc_lm()

+ [ ] Create function roll_lm() which performs rolling regressions over end points, and calculates the predicted out-of-sample values based on the coefficients from calc_lm()
adapt from roll_zscores()

+ [ ] Modify functional roll_backtest() so that it performs lapply() and returns a list of trade_func() outputs, containing the xts time series of out-of-sample returns   
trade_func() should return a list with at least two elements: time series and named vector of statistics (Sharpe, etc.)

+ [ ] Modify roll_zscores() so it updates the previous regression, instead of performing a new regression at every point in time

+ [ ] Convert roll functions from package RcppRoll to native Rcpp functions ?

+ [ ] Create functions roll() and run() in Rcpp - already done ?

+ [ ] Modify function roll_sum() so that it also calculates the rolling sum over the columns of a matrix

+ [ ] Modify function roll_vwap() so that it calls RcppRoll::roll_sum() ? 

+ [ ] Rename roll_moment(): it doesn't calculate moments, because it doesn't subtract the rolling means
deprecate function roll_moment() because it's similar to roll_vwap() ?

+ [ ] Add to function random_ohlc(): simulate random non-normal OHLC prices from Heston model

+ [ ] Fix bug in function random_ohlc() when sampling from rows of an input OHLC series (oh_lc not NULL): overnight returns are resampled into intraday periods, causing overestimation of variance.  
As a result, bootstrapped standard errors for Garman-Klass-Yang-Zhang and Yang-Zhang methods are too big.  
Possible fixes:
modify random_ohlc() so that it samples from secondly return data and aggregates to minutely OHLC data (does this solve the problem?) - save random minutely OHLC prices to file for future use  
modify random_ohlc() so that it samples from minutely return data scaled by time, and aggregates to minutely OHLC data

+ [ ] Bootstrap the range volatility estimators on random non-normal OHLC prices to check if indeed they have lowest standard error
use package meboot for maximum entropy bootstrap of time series ?
https://cran.r-project.org/web/packages/meboot/index.html

+ [ ] Add function for calculating microprice  

+ [ ] tell Joshua Ulrich that there's a bug in function TTR::volatility(), in the formula for the k coefficient in the Yang-Zhang estimator p.49
The correct formula is on p.7 of Yang OHLC Range Volatility Estimators.pdf

+ [x] In function calc_weights() add additional option for rank momentum, with "typ_e == rank" argument: rank weights using trailing Sharpe

+ [x] In function back_test() add argument co_eff to multiply the weights.

+ [x] In function back_test() add transaction costs: remember previous weights and subtract current weights from previous weights
Add argument bid_offer the bid-offer spread.

+ [x] Rename function roll_portf() to back_test()

+ [x] Add header to HighFreq.R file:
#' @useDynLib HighFreq
#' @importFrom Rcpp evalCpp
#' @exportPattern "^[[:alpha:]]+"
NULL
Remove from NAMESPACE:
useDynLib(HighFreq)
importFrom(Rcpp, evalCpp)
exportPattern("^[[:alpha:]]+")

+ [x] Add function roll_conv() for calculating the convolutions of the matrix columns

+ [x] In function calc_weights() add additional options for the typ_e argument: quadratic weights constraint (highest principal component)

+ [x] In function calc_weights() modify weight_s scaling: scale the weights to match the volatility of mean returns

+ [x] In function calc_weights() add argument called typ_e (with default value "max_sharpe"), which specifies the objective function of portfolio optimization used for calculating the weights

+ [x] Replace zoo::na.locf() with xts:::na.locf.xts()

+ [x] remove RcppParallel dependency from DESCRIPTION

+ [x] add ByteCompile: TRUE to the DESCRIPTION file

+ [x] generate man files for Rcpp functions
select the "Document" item in build menu or run R command devtools::document()

+ [x] Modify DESCRIPTION file
Added: Encoding: UTF-8
Removed from Imports: caTools, lubridate, TTR, 

+ [x] fix build error about RcppExports.R.
Add by hand to NAMESPACE:
useDynLib(HighFreq)
importFrom(Rcpp, evalCpp)
exportPattern("^[[:alpha:]]+")

+ [x] modify functional roll_apply()
Change endpoints calculation: define look_backs as a list of numeric vectors.
Calculate aggregations using lapply() loop over the look_backs, instead of sapply().
Add option to coerce output into xts series.

+ [x] create functional roll_backtest() similar to roll_apply(), but accepting two functions as arguments

+ [x] replace argument "lag" with "lagg" (to avoid confusing it with stats function lag())  

+ [x] replace calls to is.vector(in_put) with is.null(dim(in_put))

+ [x] replace "win_dow" with "look_back"

+ [x] fix bug in function run_variance() for calc_method="yang_zhang": remove win_dow from formula for co_eff.

+ [x] replace xts::.subset_xts() with brackets operator []

+ [x] add volatility, drift rate, and convexity correction to functions random_taq() and random_ohlc()  

+ [x] fix bug in random_ohlc(): transform to normal distribution before sampling from rows of OHLC (otherwise it produces negative prices)  

+ [x] move functions adjust_ohlc(), to_period() and get_symbols() from HighFreq to rutils  

+ [x] remove and/or adjust time scaling factors in run_variance(), run_skew(), and random_ohlc()

+ [x] rename functions *_OHLC and *_TAQ to *_ohlc and *_taq

+ [x] create function adjust_ohlc() that adjusts OHLC data, similar to quantmod::adjustOHLC()  

+ [x] create function get_symbols() that downloads time series data, similar to quantmod::getSymbols()  

+ [x] replace quantmod extractor functions Op(), Hi(), Lo(), Cl(), Vo() with direct subsetting: oh_lc[, 3] instead of Lo(oh_lc)

+ [x] modify function run_returns(): add argument  

+ [x] update README and web page  

+ [x] add vignettes directory and create multiple vignettes using files README and demo_HighFreq.R  

+ [x] create function random_TAQ() that returns random TAQ data

+ [x] create function random_OHLC()
returns random OHLC data used for testing for data snooping (look ahead bias) and benchmarking
Either create synthetic data or sample from real data.  
Run random data through model to test if there is data snooping.  

+ [x] add a single day of TAQ data for SPY to hf_data.RData file  

+ [x] add TLT, VXX, and SPY to hf_data.RData file  

+ [x] add lubridate to Imports in DESCRIPTION file  

+ [x] create function roll_sharpe()

+ [x] modify functions run_variance() and run_skew() to scale their outputs by the time differences, similar to run_returns()  

+ [ ] Create function sea_son() for calculating time of day (year) as fraction
The time of day can be used as an input into a seasonal model

+ [ ] Create volume-weighted Hurst and density plots  
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Create function to_period_rolling() for aggregating an OHLC time series to lower periodicity, similar to to_period(), but doesn't use end points,  

+ [ ] Modify function season_ality() to discard elements corresponding to infrequent observations ?

+ [ ] Create Rcpp function for fast rolling aggregations over endpoints

+ [ ] Aggregate data to 10-second bars (?)  

+ [ ] Add wiki  

+ [ ] Run on travis, add .travis.yml file, add Build Status tag to README.Rmd

+ [x] add vignette and automatically build vignette  

+ [ ] introduce unit testing using testthat and devtools: create /tests directory

+ [ ] Modify function skew_ohlc() to accomodate case when open price isn't equal to previous close price.  
add argument "open_to_close" with default value TRUE  

+ [ ] prove that OHLC skew formula is an estimator of skew  
Do Garman-Klass and Rogers-Satchell estimators work for processes that are not Gaussian?  
perform simulation to find out  
https://en.wikipedia.org/wiki/First-hitting-time_model  
https://en.wikipedia.org/wiki/Wiener_process  

+ [ ] Analyze paper: Shen Skew Kurtosis Stock Premiums Forecasting.pdf

+ [ ] Add logical arg as option to aggregate data or not

+ [ ] Calculate rets from scrubbed data

+ [ ] Calculate statistics (moments, quantiles) on tick and OHLC data and save them in files

+ [ ] Create function to estimate beta from HFreq data

+ [ ] Create function to forecast skewness
Show that variance is predictable over time 
Show that skewness is not predictable over time (Harvey and Siddique, 1999), 
so variables other than lagged skewness are required to forecast skewness.
Show that idiosyncratic volatility is a strong predictor of idiosyncratic skewness.

+ [x] rename functions calc_returns(), vari_ance(), skew_ohlc(), sharpe_ohlc() to run_returns(), run_variance(), run_skew(), run_sharpe()  

+ [x] rename function v_wap() to roll_vwap()  

+ [x] modify function roll_hurst() using TTR::runMax()  

+ [x] rename function hurst_ohlc() to sharpe_ohlc()  

+ [x] rename and modify function calc_rets() to calc_returns(): 
return single column with name "SPY.returns"
will break save_rets() and save_rets_ohlc()

+ [x] modify function v_wap() to accept argument x_ts  

+ [x] remove .Rproj.user directory from GitHub repository
steps:
- open Windows PowerShell from GitHub Desktop
- run: git filter-branch --tree-filter 'rm -f -R .Rproj.user' HEAD
- run: git push origin master -f
http://stackoverflow.com/questions/32228841/github-gitignore-adds-folder-previously-not-on-gitignore

+ [x] create project website for HighFreq on GitHub Pages using R Markdown  

+ [x] rename README.md to .Rmd and add more detailed description similar this to README.md:  
https://github.com/RcppCore/rcpp-gallery/blob/gh-pages/src/2016-05-27-HRP.Rmd
use rmarkdown templates
https://rud.is/b/2016/02/04/alternate-r-markdown-templates/
https://github.com/hrbrmstr/markdowntemplates
http://svmiller.com/blog/2016/02/svm-r-markdown-manuscript/




### tasks finished

+ [x] add sim_* functions using RcppArmadillo: sim_arima(), sim_garch()

+ [x] add calc_* functions using RcppArmadillo: calc_eigen(), calc_inv(), calc_scaled(), calc_lm(), calc_weights()
	
+ [x] add roll_* functions using RcppArmadillo: roll_wsum(), roll_zscores(), roll_scale(), roll_portf()

+ [x] create function remove_jumps() to remove overnight close-to-open jumps from OHLC (?)  

+ [x] replace na.locf() with rutils::na_locf()

+ [x] rename function extreme_values() to which_extreme()  

+ [x] rename function price_jumps() to which_jumps()  

+ [x] add arguments lag and sca_le to function run_returns()

+ [x] in functions calc_variance(), run_variance(), roll_variance(), and run_skew() don't perform log(oh_lc) - that can be done externally

+ [x] replace calls to lag_xts() with lag_it()

+ [x] replace calls to diff_xts() with diff_it()

+ [x] add argument sca_le to functions run_variance() and roll_variance()

+ [x] fix functions roll_hurst() and roll_sharpe() so they call roll_variance() instead of run_variance()  
in roll_hurst() replace TTR::runMax() with RcppRoll::roll_max()

+ [x] remove arguments off_set and roll_end_points from function roll_hurst()

+ [x] create function calc_variance() which calculates a single variance number from the output of run_variance()

+ [x] create function roll_variance() that replicates TTR::volatility()  
clone run_variance(), but modify it by subtracting the means
use functions RcppRoll::roll_var() and rutils::roll_sum()
add correct coefficient co_eff for yang_zhang method

+ [x] modify comments for function run_variance() to explain that it's only an indicator, not an estimator

+ [x] modify function run_returns(): remove time scaling, calculate percentage returns  

+ [x] apply Hampel median filter to scrub data: that's what HighFreq does already  
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
update the documentation to reflect that HighFreq already uses Hampel median filter

+ [x] create functional roll_apply(), similar to xts:::rollapply.xts() and xts::period.apply()  
use apply_rolling() from utilLib

+ [x] rename function roll_agg() to roll_moment(), and its argument esti_mator to mo_ment  

+ [x] modify function hurst_ohlc() to calculate (C-O)/(H-L)

+ [x] create function roll_hurst() for rolling Hurst exponent, similar to roll_sum()  
Detrended fluctuation analysis - is it like variance ratios?
Hurst analysis is related to Detrended fluctuation analysis:
https://en.wikipedia.org/wiki/Detrended_fluctuation_analysis
HurstIndex() from PerformanceAnalytics is wrong because it uses range of returns, instead of range of cumulative returns!
variance ratio test
http://quant.stackexchange.com/questions/7666/using-variance-ratios-to-test-for-mean-reversion

+ [x] move function roll_sum() from HighFreq to rutils

+ [x] add to function season_ality() in_dex argument

+ [x] perform bootstrap estimation of standard errors for all the methods in function vari_ance()  
benchmark to random OHLC

+ [x] add to function vari_ance() the methods "garman.klass_yz" and "yang.zhang"  

+ [x] modify functions vari_ance() to accomodate case when open price isn't equal to previous close price - methods "garman.klass_yz" and "yang.zhang"  

+ [x] rename function vol_ohlc() to vari_ance()

+ [x] create function to_period()  

+ [x] rename argument agg_fun to esti_mator, in functions agg_regate() and roll_agg()  

+ [x] remove calc_method argument from agg_regate() and roll_agg() - instead use "..." argument

+ [x] rename agg_ohlc and roll_agg_ohlc() to agg_regate() and roll_agg()  

+ [x] dereference all external functions using "::", i.e. rutils::na_me()

+ [x] add @export to roxygen code  

+ [x] convert all code from nrow() and ncol() to NROW() and NCOL()  

+ [x] replace strsplit(colnames(ohlc)[1], split="[.]")[[1]][1] with rutils::na_me(ohlc)  

+ [x] fix roxygen .Rd documentation file building error - name at end of hf_data.R file was wrong - should be the names of objects, i.e. "SPY", "sym_bol", not the file name  

+ [x] create data documention  

+ [x] rename moment_ohlc() and roll_moment_ohlc() to agg_ohlc and roll_agg_ohlc()
mom_fun to agg_fun

+ [x] create function hurst_ohlc() for calculating Hurst exponent from OHLC data
OHLC data naturally lends itself to Hurst analysis: ratio of (H-L)/(C-O)

+ [x] in moment_ohlc() and roll_moment_ohlc() removed log of ohlc
moment_ohlc() and roll_moment_ohlc() should pass ohlc to skew_ohlc() and vol_ohlc(), etc., not log ohlc

+ [x] modify skew_ohlc() and vol_ohlc() to accept ohlc, not log ohlc, and to apply log internally

+ [x] include rutil package 

+ [x] create function for performing daily, weekly, and monthly seasonality aggregations

+ [x] rename functions run_*() to roll_*()

+ [x] rename save_OHLC() to save_scrub_agg()

+ [x] in save_rets_OHLC() update documentation

+ [x] in save_OHLC() combine sapply loops into one

+ [x] in save_OHLC() and save_rets() pass scrub params to scrub_agg

+ [x] add timezone to argument list

+ [x] create function save_TAQ()
	saves scrubbed TAQ and/or OHLC data in daily files
	similar to save_OHLC, but doesn't aggregate and saves into multiple files

+ [x] create function calc_rets()
	calculate returns of time series

created function save_rets() (similar to save_OHLC): 
	scrub and aggregate data, calculate returns, and save them

created function save_rets_OHLC()
	similar to save_rets, but assumes clean OHLC input data
	- no scrubbing or aggregation


### tasks deprecated

+ [ ] Modify function run_returns() to perform sapply() if argument has multiple columns ?

+ [ ] Remove extra increment of 1 in start_points index in roll_apply() - no, because otherwise it would create overlaps when aggregating returns (for example)  
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))]
instead of:
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))] + (NROW(oh_lc) > (len_gth+1))

+ [ ] Modify "close" method in function run_variance() by averaging open and close prices - no creates a bias underestimates variance  

+ [ ] subtract mean in functions run_variance() and run_skew() - no  

+ [ ] Convert function season_ality() to use split.xts() (?)  

+ [ ] Replace caTools with TTR functions (?)  
only runquantile() is called from caTools  
but not easy to replace runquantile(), because no equivalent TTR function  
would require rewriting extreme_values() and price_jumps(), and then benchmarking  

+ [ ] use .subset_xts() (?)

+ [ ] Rename save_rets_OHLC to rets_OHLC (?)  

+ [ ] Calculate volume-weighted moments and compare them to standard moments
add volume-weighting to vol_ohlc() and skew_ohlc()


### commits

# commit 05-18-16
added rutils to depends in DESCRIPTION
moved do_call_rbind to rutils

# commit 05-17-16 bis
Added function season_ality()

# commit 05-17-16
Renamed functions from run_* to roll_*

# commit 11-03-15
fixed function v_wap() from Ad() to Cl()

# commit 10-03-15
added functions run_sum() and v_wap()

# commit 05-29-15
Finished R/Finance_2015 presentation

# commit 03-27-15
added timezone to argument list
updated functions: calc_rets, save_rets

# commit 03-16-15
added functions: calc_rets, save_rets, save_TAQ
updated functions: save_OHLC, scrub_TAQ
added "data" folder
updated roxygen documentation


# commit 03-01-15
added roxygen documentation

created functions:
save_OHLC
scrub_TAQ

scrub_agg:
change time zone
to trading hours
merge duplicate time stamps using make.index.unique - no
remove duplicate time stamps using duplicated
calculate mid price?
NA omit mid price
convert NA volumes to zero
replace NA trade prices with mid prices
scrub on mid price:
	bid-offer spread
	if bid-offer spread too wide then use trade price?
	hairlines


in save_OHLC
add save dir
coerce using quantmod.OHLC? - no

create function save_TAQ:
save scrubbed daily TAQ data to daily files
use quantmod standard headers - quantmod naming conventions

create function similar to getSymbols (?):
load and rbind TAQ data (without scrubbing or aggregating)


# commit 02-17-15
renamed many functions and variables
added roxygen comments
added demo folder and files
edited README
updated HighFreq-package.Rd



