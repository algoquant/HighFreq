############
### ToDo list for package HighFreq: high frequency data scrubbing

### Scripts for package building

## Steps for installing package called my_package, containing Rcpp code:
1. Create empty package directory with Rcpp::Rcpp.package.skeleton()
2. In the R directory create a file called my_package.R and add the header:
#' @useDynLib my_package
#' @importFrom Rcpp evalCpp
#' @exportPattern "^[[:alpha:]]+"
NULL
Add your R functions below the header.
3. Finally, from the Build menu run Clean and rebuild.


## How to update the NAMESPACE file after adding a new function
Edit the NAMESPACE file and add a line to export the new function new_func(): 
export(new_func)


## Steps to fix the NAMESPACE file after adding a new function - sometimes produces a bad NAMESPACE file
1. In RStudio from Build menu run Document - usually produces a bad NAMESPACE file
2. Edit the NAMESPACE file again and remove all lines that don't contain export() - no longer necessary
3. Add at the top of NAMESPACE file the lines:
useDynLib(HighFreq)
importFrom(Rcpp, evalCpp)


## Build scripts:

# Install package from source on local drive
install.packages(pkgs="C:/Develop/R/HighFreq", repos=NULL, type="source")
# Install package from source on local drive using R CMD
R CMD INSTALL C:\Develop\R\HighFreq
# Install NPE package from local drive
setwd("C:/Develop/R/HighFreq")
install.packages(pkgs="C:/Develop/R/HighFreq", repos=NULL, type="source")
# Install package from Github
devtools::install_github(repo="algoquant/HighFreq", force=TRUE)
# Document the package - run R command
devtools::document()
# Build vignette package reference manual from *.Rd files
system("R CMD Rd2pdf /Users/jerzy/Develop/HighFreq")
cd /Users/jerzy/Develop/HighFreq
R CMD Rd2pdf /Users/jerzy/Develop/HighFreq/



### Comments

# Applying different models in a loop can be achieved using function pointers
First create a function pointer from its string name via an if-else statement.  Then reference (apply) the function pointer inside the loop.
Standard function pointers are good enough - there's no need for Rcpp::XPtr function pointers.  There's also no need for functionals (functions of functions). 

# The advantage of functors compared to functions, is that they can have state variables that are persistent between function calls
Functors are C++ class objects that act like functions.

# When performing a rolling calculation, it's better to apply a single lag to a time series outside the loop instead of lagging it inside at each end point

# Passing pointers as arguments into functions increases their speed by 30% or more for very large vectors with a million or more elements.  But it can make it harder to pass in arguments when calling them from inside other functions.  The solution is to avoid nesting function calls, and instead create intermediate variables, and pass them into functions.  Passing in pointers also allows using const arguments so that they can't be modified inside the function.

# Volume weighted volatility is higher than simple average volatility because volumes are higher when volatility is higher. 

# The yang_zhang method has the lowest standard error assuming normal distribution, but not necessarily for fat-tailed distributions.
In addition, the yang_zhang method has lower bias caused by finite sampling.
The rogers_satchell method has the biggest bias caused by finite sampling and opening price jumps, and seriously underestimates the variance.

# Theoretically, the Yang-Zhang (YZ) and Garman-Klass-Yang-Zhang (GKYZ) range variance estimators are unbiased and have up to seven times smaller standard errors than the standard close-to-close estimator.  But in practice, prices are not observed continuously, so the price range is underestimated, and so is the variance when using the YZ and GKYZ range estimators.  Therefore in practice the YZ and GKYZ range estimators are biased (underestimate volatility).  In addition, the standard errors are reduced less than by the theoretical amount, for the same reason. 

# Using the average of open and close prices in the standard variance estimator (instead of just the close prices) doesn't reduce the standard error.

# High frequency data has three tenor horizons: daily (daily or lower frequency of data), intraday (secondly to daily frequency of data), and sub-second tenor horizons (sub-secondly or higher frequency of data).
At the sub-second tenor horizon, returns are dominated by noise and the bid-ask bounce.
Returns are dominated in their scale by the volatility, and they have no discernable trend.
At the sub-second horizon technical indicators are meaningless, and instead traders analyze the order book for clues about future returns.
At the intraday tenor horizon volatility, skew, and kurtosis are high, and mean-reversion dominates trending.
Technical indicators based on past returns and trading volumes can offer clues about future returns.
At the daily tenor horizon skew and kurtosis are small, and trending dominates mean-reversion.

# Calculating returns on 1-second bars doesn't make sense for two reasons: 
First, because the changes in price are very small, comparable to the precision of prices (number of significant digits).
As a result, price changes on 1-second bars are either zero or low multiples of the precision. 
Second, the 1-second bar prices bounce randomly between static bid and ask prices (the bid-ask bounce).  
Therefore 1-second bar returns carry almost no information.


### Tasks to-do

should be in the range
must be in the range

+ [ ] Modify all the calc_*() and run_*() functions to remove zero values from the data since these are missing values, so they skew the outputs

+ [ ] Fix run_reg() - the regression formula is only valid for a single predictor or for several orthogonal predictors

+ [ ] In run_reg() define alphas
Express alpha as the exponential average of the residuals?

+ [ ] Replace the word "running" with "online" or "streaming"

+ [ ] Update the documentation for all the running functions run_*() - switch terms in the online formulas

+ [ ] Deprecate run_zscores() because run_reg() is the new version?

+ [ ] Add t-values of the alpha and betas to run_reg()

+ [ ] Compare the outputs of functions run_reg() versus roll_reg()
Find the lambda parameter which produces similar values for a given look_back parameter.


+ [ ] Implement recursive least squares regression - recursive formula is analogous to Kalman filter
Nadagouda Recursive Least Squares Regression Kalman Filter
https://dingyan89.medium.com/least-squares-recursive-least-squares-kalman-filters-and-sensor-fusion-ed13f6242e9e

+ [ ] Create the function run_covmat() - for recursively updating the covariance matrix by reference using lambda and today's returns - using recursive technique from run_covar()


+ [ ] Calculate the mean portfolio returns ignoring zero stock returns, because including zero returns biases the estimate away from the actual mean portfolio returns

+ [ ] Create online functions run_sharpe() and run_kelly()
Apply volume weighting.
Add minvol parameter equal to the floor of the volatility, to prevent the ratios from blowing up when the volatility is very small or zero.

+ [ ] Implement incremental PCA IPCA
Cardot Online Principal Component Analysis.pdf

+ [ ] Create function calc_alpha() to calculate the performance of an asset relative to an index. 
calc_alpha() should implement several different methods, with the default being Jensen's alpha. 
One robust method should be the Wilcoxon W statistic.
Another robust method should be the Kruskal-Wallis H statistic as follows:
Combine the given asset returns with the index returns into a single vector.
Rank the vector of combined returns.
Calculate the H statistic as the difference between the sum of the ranks of the asset returns minus the sum of the ranks of the S&P500 returns.
The H statistic is reminiscent of the difference between the mean asset returns minus the mean S&P500 returns.

+ [ ] Deprecate the function roll_zscores() and replace it with roll_reg()

+ [ ] Create a function that de-means the columns of a matrix in-place
Performs these operations:
predictor <- apply(predictor, 2, function(x) (x-mean(x)))
Or
predictor <- t(t(predictor) - colMeans(predictor))

+ [ ] Create function to calculate the rolling variance and covariance from the rolling sums of returns and squared returns

+ [ ] Enhance the function calc_var() to calculate the variance for overlapping aggregated returns: the variance of returns aggregated over k time periods - the prototype is in test_temp.cpp

+ [ ] Create function run_alpha() for calculating alpha, beta, and the idiosyncratic stock returns
Set the response argument to be the stock returns and the market factors argument be the returns of ETFs.
Adapt from run_covar()

+ [ ] Modify roll_zscores() so it updates the previous regression, instead of performing a new regression at every point in time

+ [ ] Make function back_test() parallel using package RcppParallel

+ [ ] Create function calc_hurst_range() for the Hurst using the rescaled range

+ [ ] Enhance the function diffit() to calculate the fractional differencing scaled by the square root of the volume - to make it more stationary

+ [ ] Update function roll_stats() to use function pointers

+ [ ] Pass model function and its parameters into back_test() as a vector or a list
http://gallery.rcpp.org/articles/passing-cpp-function-pointers/
https://stackoverflow.com/questions/43616778/passing-user-created-c-functions-in-rcpp-as-arguments
https://stackoverflow.com/questions/51274385/calling-rcpp-function-with-xptr-and-function-only-xptr-case-works
https://stackoverflow.com/questions/50548060/generating-xptr-from-rcpp-function
https://stackoverflow.com/questions/49539341/rcpp-lost-on-how-to-utilize-rcppxptr-to-wrap-a-pointer

+ [ ] Pass parameters to function back_test() using parameter pack and dots or va_list argument to C++ functions - not easy or possible - use Rcpp::List instead
https://stackoverflow.com/questions/3530771/passing-variable-arguments-to-another-function-that-accepts-a-variable-argument
https://stackoverflow.com/questions/20901811/function-with-three-dots-argument
https://codesteps.com/2014/05/16/how-to-pass-variable-number-of-arguments-to-c-cpp-functions/
https://kevinushey.github.io/blog/2016/01/27/introduction-to-c++-variadic-templates/
https://stackoverflow.com/questions/39792417/what-does-this-three-dots-means-in-c
https://vcpptips.wordpress.com/tag/three-dots-as-parameter/
https://xenakios.wordpress.com/2014/01/16/c11-the-three-dots-that-is-variadic-templates-part/
https://en.cppreference.com/w/cpp/language/parameter_pack
https://stackoverflow.com/questions/3351056/create-va-list-dynamically

+ [ ] Modify function back_test() so it accepts a C++ prediction/forecasting function (functor, function pointer)  
https://stackoverflow.com/questions/7143120/convert-string-to-variable-name-or-variable-type
http://bytes.com/forum/thread656124.html

+ [ ] Create a function called calc_regptr() for calculating a pointer to a regression function from a function name (string)
It should accept a string with a function name and return a pointer to the function with that name.
It should return a pointer to one of the regression functions: calc_reg(), calc_var(), calc_skew() or calc_kurtosis().

+ [ ] Create function calc_table() to calculate the contingency table 
Function calc_table() is in /Users/jerzy/Develop/Rcpp/fun_stl.cpp

+ [ ] Calculate the covariance matrix in two steps: first perform clustering and then calculate the covariance matrix of the clusters

+ [ ] Create function calc_covar() to calculate a nonparametric (robust) covariance matrix
Adapt function calc_var()
Calculate the MAD covariance - the covariance based on the median, analogous to the MAD Median Absolute Deviation.
Several possible methods are: 
The covariance is equal to the difference between the variance of the sum minus the variance of the difference: 
cov = (var(r1+r2) - var(r1-r2))/4
Gerber covariance estimator.
Quantile estimator: weighted sums of the median and higher quantiles of asset returns.
Hodges-Lehmann estimator: 

+ [ ] Add Portfolio Optimization using the Gerber Statistic
http://nextlevelanalytics.github.io/2016/05/26/Gerber/
Gerber Statistic Portfolio Optimization.pdf

+ [ ] Adapt from package RiskPortfolios by Ardia - it's pure R code

+ [ ] Adapt from package roll parallel rolling aggregations
https://github.com/jjf234/roll

+ [ ] Add rolling rank regression from package roll:
https://github.com/jjf234/roll

+ [ ] Introduce a control argument in functions calc_mean(), calc_var(), calc_skew() and calc_kurtosis()?

+ [ ] Introduce shrinkage of returns to the PCAs - is it equivalent to parameter shrinkage (dimension reduction)? Maybe, even if it's not equivalent it's good anyway

+ [ ] Remove Rcpp features like Rcpp::Nullable to make the code closer to pure C++
https://stackoverflow.com/questions/2537942/nullable-values-in-c
https://en.cppreference.com/w/cpp/named_req/NullablePointer

+ [ ] Convert some loops to STL iterators: iterators are pointers to vector and matrix elements
It may be simpler to use std::accumulate().
https://www.geeksforgeeks.org/iterators-c-stl/

+ [ ] Replace only some Rcpp syntax with Armadillo or Boost or STL
There are several advantages of using Rcpp::NumericVector instead of std::vector<double> :
NumericVector avoids deep copy of data between R and C++
NumericVector provides access to Sugar functions.
For example, if you replace NumericVector with std::vector<double> then you lose flexibility and need two copies of every function - one for integer and one for double.
cpp::NumericVector over std::vector<double>
https://stackoverflow.com/questions/41602024/should-i-prefer-rcppnumericvector-over-stdvector

+ [ ] In function calc_var() add robust dispersion estimators

+ [ ] In function calc_kurtosis() update the method nonparametric

+ [ ] In function roll_reg() add option to perform rolling predictions using the regressions

+ [ ] In function calc_reg() add additional types of regressions: robust Theil-Sen regression, rank regression, quantile regression, PCA regression with shrinkage, etc.
It should calculate Pearson, Spearman, and Kendall correlations.
It should return a named vector of coefficients, tvals, and zscore - works only for Rcpp.

+ [ ] In function calc_lm() add Boolean parameter to add intercept column to explanatory matrix

+ [ ] Modify rolling Theil-Sen function to return a column of the MAD of pair slope estimates

+ [ ] Deprecate function roll_conv_ref() ?
Does it actually calculate by reference?

+ [ ] Modify function back_test() so it returns a matrix of strategy returns and positions, not just returns

+ [ ] Modify back_test() add parameter for lagging the weights - for applying the weights with an extra lag

+ [ ] Convert all time loops to loops over the end points, using calc_endpoints() and calc_startpoints()

+ [ ] Create a function called roll_quantile() for the rolling quantile

+ [ ] Create function calc_quantile() to calculate or update the quantile of a vector of numbers
The value of the quantile can be updated based on the old quantile value and the new updated vector values.
If there are very few new vector values and if they're all far from the old quantile value, then the quantile may remain unchanged.
Apply it to the calculation or rolling quantiles.

+ [ ] Create function calc_ret_stats() for calculating aggregations (statistics) over a vector of returns
Examples of statistics are the mean, median, Sharpe ratio (t-value), Wilcoxon statistic, etc.

+ [ ] Create a function called calc_quantile() for calculating the quantiles of the columns of a matrix
It should accept a vector of probabilities and return a matrix.

+ [ ] In function roll_var() use moment update formulas from package fromo: Pebay Fast Moments.pdf
Calculate rolling variance efficiently (used by package fromo):
https://www.johndcook.com/blog/standard_deviation/

+ [ ] Combine functions sim_ou() and sim_schwartz() into a single function

+ [ ] Modify function calc_scaled() so it performs the calculation in place, without copying the matrix in memory
That may not always be correct, for example in the case of rolling calculations.

+ [ ] Fix function mult_mat_ref() - it doesn't do anything - it doesn't multiply the matrix
Is it a problem only on the Mac because of incompatible compiler?

+ [ ] In functions calc_reg() and roll_reg() add an argument called "method" for scaling the residuals

+ [ ] Create aggregation function agg_regate() similar to roll_ohlc(), which aggregates returns, prices, etc. to time series with lower periodicity.
Worker agg_ohlc()

+ [ ] Fix scaling in calc_weights() ?

+ [ ] Explain why roll_wsum() is slower than filter()

+ [ ] Explain why roll_wsum() output is different from roll_conv()

+ [ ] Create function calc_drawd() for calculating the drawdown in R code

+ [ ] Create function calc_alpha() for calculating the alpha and beta, and their t-values and p-values

+ [ ] Create function calc_sharpe() for calculating the Sharpe, Sortino, Calmar, and ratios in R code

+ [ ] Create function fit_ar() to fit an AR process using matrix algebra

+ [ ] Create function fit_ou() to fit an OU process using matrix algebra

+ [ ] Create function fit_adf() to calculate the ADF test statistic using matrix algebra

+ [ ] Create function fit_garch() to fit a GARCH process using a solver

+ [ ] Rename calc_lm() to fit_lm(), and calc_reg() to fit_reg() ?

+ [ ] Create functions roll_max() and roll_min() using a look-back interval

+ [ ] Modify functions calc_weights() and back_test() to perform rolling portfolio optimization in the simplified case of orthogonal Forecastable Component Analysis (FCA)

+ [ ] Finish the function remove_dup()

+ [ ] Create online function for scrubbing jumps from streaming prices

+ [ ] Create online function for Hampel filter

+ [ ] In function back_test() calculate the mean of returns using function calc_mean() and the covariance of returns using function calc_covar()?
Add weight scaling instead of in calc_weights()?

+ [ ] In function calc_weights() fix scaling method voleqw - the below code should produce TRUE
weightsr <- drop(invmat %*% colmeans)
weightsr <- weightsr*sd(rowMeans(returns))/sd(returns %*% weightsr)
weightcpp <- drop(HighFreq::calc_weights(returns, eigen_max=eigen_max, alpha=alpha, scalew="voleqw"))
all.equal(weightcpp, weightsr)

+ [ ] In function calc_mean() add shrinkage of returns?

+ [ ] In function back_test(), scale the weights to match the volatility of the equally weighted portfolio?  No - that belongs to calc_weights()

+ [ ] In function calc_weights(), make the weights scaling separate from the weight calculations.

+ [ ] Modify calc_weights() shrink the returns to a portfolio with weights proportional to the asset betas

+ [ ] Add roxygen2 options for inherited parameters - but doesn't work in Rcpp
Use the example roxygen code in R code:
//' @inheritParams which_extreme

+ [ ] Fix the inheritParams Roxygen2 option in HighFreq.cpp
After installing roxygen2:
devtools::install_github("r-lib/roxygen2")
These Roxygen2 options don't work
@inheritParams calc_var
@inherit calc_var return params
https://gallery.rcpp.org/articles/documenting-rcpp-packages
https://cran.r-project.org/web/packages/roxygen2/news/news.html
https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html#inheriting-documentation-from-other-topics
https://stackoverflow.com/questions/65739109/r-r6-inheritance-with-roxygen2-class-parentclass-is-not-exported-by-namespa

+ [ ] Add unit testing using testthat and devtools: create /tests directory

+ [ ] Modify function roll_vwap() so that it calls RcppRoll::roll_sum() ? 

+ [ ] Convert function calls to roll functions from package RcppRoll to native Rcpp functions: roll_max() and roll_var()

+ [ ] Perform rolling regressions over trading time - using a time-dependent look-back interval, so that the look-back interval always spans the same traded volume  
Inoue Rolling Regressions Time Series Bias Variance Tradeoff.pdf
Easley Volume Clock Trading Paradigm.pdf
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Run Rcpp11 code
install.packages("Rcpp11")
devtools::install_github("Rcpp11/attributes")
attributes::sourceCpp(file="/Users/jerzy/Develop/Rcpp/test_dots_copy.cpp")

+ [ ] Create a function called na_locf()
// [[Rcpp::export]]
NumericVector na_locf(NumericVector x) {
  NumericVector output = Rcpp::clone(x);
  double lastNonNA = NA_REAL;
  int n = x.size();

  for (int i = 0; i < n; ++i)
  {
    double value = output[i];
    if (!ISNAN(value))
      lastNonNA = value;
    else
      output[i] = lastNonNA;
  }
  return output;
}
arma::uvec any_na_x(const NumericMatrix& x) {
  int n_rows_x = x.nrow();
  int n_cols_x = x.ncol();
  arma::uvec result(n_rows_x);
  
  for (int i = 0; i < n_rows_x; i++) {
    int any_na = 0;
    int j = 0;
    
    while ((any_na == 0) && (j < n_cols_x)) {
      if (std::isnan(x(i, j))) {
        any_na = 1;
      }
      j += 1;
    }
    result[i] = any_na;
  }
  return result;
}
arma::uvec any_na_xy(const NumericMatrix& x, const NumericMatrix& y) {
  int n_rows_xy = x.nrow();
  int n_cols_x = x.ncol();
  int n_cols_y = y.ncol();
  arma::uvec result(n_rows_xy);
  
  for (int i = 0; i < n_rows_xy; i++) {
    int any_na = 0;
    int j = 0;
    int k = 0;
    while ((any_na == 0) && (j < n_cols_x)) {
      if (std::isnan(x(i, j))) {
        any_na = 1;
      }
      j += 1;
    }
    while ((any_na == 0) && (k < n_cols_y)) {
      if (std::isnan(y(i, k))) {
        any_na = 1;
      }
      k += 1;
    }
    result[i] = any_na;
  }
  return result;
}

+ [ ] Create a function in RcppArmadillo which replicates the function zoo::na.fill(), and which replaces NA, NaN, and Inf values, but in place, without returning a value

+ [ ] Add functions for median and MAD in Rcpp
http://gallery.rcpp.org/articles/robust-estimators/

+ [ ] Apply STL algorithm function to perform find/which operation
http://adv-r.had.co.nz/Rcpp.html#stl

+ [ ] Add very fast RcppArmadillo functions: whi_ch(), cum_sum(), select_sub_mat()
http://arma.sourceforge.net/docs.html
https://stackoverflow.com/questions/23849354/equivalent-of-which-function-in-rcpp

+ [ ] Create new roll functions using RcppRoll::rollit() ?

+ [ ] Add to back_test() the simulation with limit orders

+ [ ] Remove all parallel code and references to parallel packages from HighFreq  

+ [ ] Create function predict_lm() which calculates the predicted out-of-sample values based on the coefficients from calc_lm()

+ [ ] Modify functional roll_backtest() so that it performs lapply() and returns a list of trade_func() outputs, containing the xts time series of out-of-sample returns   
trade_func() should return a list with at least two elements: time series and named vector of statistics (Sharpe, etc.)

+ [ ] Create functions roll() and run() in Rcpp - already done ?

+ [ ] Add to function random_ohlc(): simulate random non-normal OHLC prices from Heston model

+ [ ] Apply dynamic dispatch to create s single function to handle both vector and matrix arguments
https://gallery.rcpp.org/articles/dynamic-dispatch-for-sparse-matrices/
https://stackoverflow.com/questions/27466319/templated-matrix-in-rcpp
https://stackoverflow.com/questions/22513529/templated-function-for-sparse-and-dense-matrices-in-rcpparmadillo
https://stackoverflow.com/questions/45163887/how-can-i-use-a-c-function-template-in-r-via-rcpp

+ [ ] Fix bug in function random_ohlc() when sampling from rows of an input OHLC series (oh_lc not NULL): overnight returns are resampled into intraday periods, causing overestimation of variance.  
As a result, bootstrapped standard errors for Garman-Klass-Yang-Zhang and Yang-Zhang methods are too big.  
Possible fixes:
modify random_ohlc() so that it samples from secondly return data and aggregates to minutely OHLC data (does this solve the problem?) - save random minutely OHLC prices to file for future use  
modify random_ohlc() so that it samples from minutely return data scaled by time, and aggregates to minutely OHLC data

+ [ ] Bootstrap the range volatility estimators on random non-normal OHLC prices to check if indeed they have lowest standard error
use package meboot for maximum entropy bootstrap of time series ?
https://cran.r-project.org/web/packages/meboot/index.html

+ [ ] Create a function for calculating microprice  

+ [ ] Tell Joshua Ulrich that there's a bug in function TTR::volatility(), in the formula for the k coefficient in the Yang-Zhang estimator p.49
The correct formula is on p.7 of Yang OHLC Range Volatility Estimators.pdf

+ [ ] Create function sea_son() for calculating time of day (year) as fraction
The time of day can be used as an input into a seasonal model

+ [ ] Create volume-weighted Hurst and density plots  
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Modify function season_ality() to discard elements corresponding to infrequent observations ?

+ [ ] Create Rcpp function for fast rolling aggregations over endpoints

+ [ ] Aggregate data to 10-second bars (?)  

+ [ ] Add wiki  

+ [ ] Run on travis, add .travis.yml file, add Build Status tag to README.Rmd

+ [ ] Introduce unit testing using testthat and devtools: create /tests directory

+ [ ] Modify function skew_ohlc() to accomodate case when open price isn't equal to previous close price.  
add argument "open_to_close" with default value TRUE  

+ [ ] Prove that OHLC skew formula is an estimator of skew  
Do Garman-Klass and Rogers-Satchell estimators work for processes that are not Gaussian?  
perform simulation to find out  
https://en.wikipedia.org/wiki/First-hitting-time_model  
https://en.wikipedia.org/wiki/Wiener_process  

+ [ ] Add logical arg as option to aggregate data or not

+ [ ] Calculate rets from scrubbed data

+ [ ] Calculate statistics (moments, quantiles) on tick and OHLC data and save them in files

+ [ ] Create function to estimate beta from HFreq data

+ [ ] Create function to forecast skewness
Show that variance is predictable over time 
Show that skewness is not predictable over time (Harvey and Siddique, 1999), 
so variables other than lagged skewness are required to forecast skewness.
Show that idiosyncratic volatility is a strong predictor of idiosyncratic skewness.




### Tasks finished

+ [x] Create the function calc_invrec() for calculating the inverse of a matrix recursively using the Schulz formula

+ [x] Create the function calc_invref() for calculating the inverse of a matrix in place (pass by reference) using arma::inv()

+ [x] Add sandbox folder for testing code to be incorporated into production

+ [x] Rename variable "matrix" to "matrixv"

+ [x] Rename variable "tseries" to "matrixv" or "vectorv" - in matrix functions

+ [x] Rename variable "vector" to "vectorv"

+ [x] Replace the word "running" with "trailing"

+ [x] Modify the running functions run_var() and run_covar() to avoid leading zeros in volatility, skewness, kurtosis

+ [x] Update function calc_hurst() to use a vector of aggregation intervals

+ [x] Create a function called param_reg() for creating a named control list of regression parameters that can be passed as an argument to the functions calc_reg() and roll_reg()

+ [x] Create a function called param_portf() for creating a named control list of portfolio optimization parameters that can be passed as an argument to the functions calc_weights() and back_test()

+ [x] Introduce control arguments in functions calc_reg() and roll_reg()

+ [x] Add control list argument to function back_test() and pass it to calc_weights(), instead of passing many arguments

+ [x] Introduce control arguments in functions calc_weights() and back_test()

+ [x] Modify the function roll_fun() for rolling aggregations of functions 
Rename roll_fun() to roll_moment().
It should accept a string with a function name, and use the pointer to that function to calculate rolling aggregations over end points.
It should dispatch the moment function: calc_mean(), calc_var(), calc_skew() and calc_kurtosis().

+ [x] Create a function called calc_momptr() for calculating a pointer to a moment function from a function name (string)
It should accept a string with a function name and return a pointer to the function with that name.
It should return a pointer to one of the moment functions: calc_mean(), calc_var(), calc_skew() or calc_kurtosis().
Implemented in calc_momptr() and roll_moment().

+ [x] Pass a function pointer as an argument to a C++ function (functional)
Examples for straight C++ functions are in test_funptr.cpp and funptr_drivers.R
Functionals can be created in straight C++, but they can't be exported to R, because the R interface to C doesn't have a notion of functionals.
The package RcppXPtrUtils can create pointers to R functions that can be passed to C++ functionals.  But the functions can only be created from text code using RcppXPtrUtils::cppXPtr().
Examples are in xptr_drivers.R and test_xptr.cpp.

+ [x] Adapt function pointers - examples for straight C++ functions are in test_funptr.cpp and funptr_drivers.R
https://gallery.rcpp.org/articles/passing-cpp-function-pointers/
https://en.wikipedia.org/wiki/Function_pointer#Example_in_C

+ [x] Adapt STL code from util_stl_fun.cpp

+ [x] Create function to calculate the run length encoding of a vector
Functions encode_it() and decode_it() in /Users/jerzy/Develop/Rcpp/fun_stl.cpp
File /Users/jerzy/Develop/Rcpp/drivers_stl.R

+ [x] It's not possible to create an Rcpp function with dots because the .Call() interface in R doesn't support them
https://stackoverflow.com/questions/24590946/passing-many-argumentes-by-ellipsis-in-rcpp
The .Call() interface in R only supports C language structures, not C++.
The only workaround is passing a list of parameters and unpacking them.

+ [x] Fix the functions calc_var_ag() and calc_var_ohlc_ag() - use calc_endpoints() without stub intervals

+ [x] Modify the function calc_endpoints() to make stub intervals optional
Add Boolean argument stubs: 
If TRUE include stub intervals (the default) - then end points always start at zero and end at (length-1).
If FALSE make all intervals equal to step (exclude some end points).

+ [x] Split the file HighFreq.cpp into multiple files - doesn't work
The functions from the separate files are missing their default values.  Even though the default values are in the header definitions.
https://stackoverflow.com/questions/56204031/rcpp-function-default-values-in-header-file

+ [x] Convert all std::vector to arma::vec 

+ [x] Fix run_max() and run_min() formulas

+ [x] Modify function run_var() so that it calculates the variance the same way as function sim_garch() with parameter is_random=FALSE - No
Rename run_var() to roll_var_garch() ? No
Instead, subtract the means from returns before squaring - otherwise it produces negative variance.

+ [x] In function roll_var() calculate the rolling variance from the rolling sums of returns and the rolling sums of squared returns
This avoids calling calc_var() in loop.
Not necessary since calc_var() calls arma::var() so it's pretty fast.

+ [x] Rename eigen_max to dimax

+ [x] Rename "eigen shrinkage" to "dimension reduction" or "parameter shrinkage"

+ [x] In function calc_weights() introduce independent ranking, centering and scaling of weights: rankw, centerw, rankcenterw, scalew, centerscalew
Modify the argument scale from type Boolean to type methodenum.
Rename the argument scale to scalew.
Rename methods rank_sharpe/sharpem, rankrob/robustm, min_var/minvarlin, min_varpca/minvarquad, max_sharpe/maxsharpe, max_sharpe_median/maxsharpemed

+ [x] In function calc_weights() modify the method rank because it's identical to ranksharpe
Rename methodenum::rank to methodenum::kellym.
Calculate the momentum weights equal to the Kelly ratios: the returns divided by their variance.

+ [x] Update the documentation for calc_weights() and calc_inv()

+ [x] Fix functions calc_lm() and calc_reg()
Rename stderr to stderrv.  Add prefix Rcpp:: to function calls.

+ [x] Rename mult_vec_mat() to mult_mat()
When dimensions are wrong, don't produce error, just return the original matrix.
Change by_col to byrow.

+ [x] Create a function that multiplies the columns of an xts or matrix by a vector of weights, without adding together the columns as in (prices %*% weights)
This is done by mult_mat().
Equivalent to this in R:
prices <- lapply(1:NCOL(prices), function(i) weights[i]*prices[, i])
prices <- rutils::do_call(cbind, prices)

+ [x] In functions calc_reg() and roll_reg() change the default to intercept=TRUE

+ [x] Simplify variable names by removing underscores: sym_bols -> symbolv, x_ts -> xtes
Use last letter "d" for dates, "t" for times, "v" for variables, vectors and lists, "s" for series, etc.
Run shell script:
/Users/jerzy/Develop/lecture_slides/scripts/run.sh
chmod +x run.sh
./run.sh

+ [x] Modify function run_mean() to calculate the running weighted mean if the weight vector is passed as an argument

+ [x] Fix run_reg() - keep old version as run_rego()
Replace
vars.row(it) = lambda1*(vars.row(it) - arma::square(means_pred.row(it))) + lambda*vars.row(it-1);
With
vars.row(it) = lambda1*arma::square(predictor.row(it)-means_pred.row(it)) + lambda*vars.row(it-1);
Replace
varz.row(it) = lambda1*arma::square(resids.row(it) - resids.row(it-1)) + lambda*varz.row(it-1);
With
varz.row(it) = lambda1*arma::square(resids.row(it) - meanz.row(it)) + lambda*varz.row(it-1);

+ [x] In functions calc_reg() and roll_reg() make the intercept term optional

+ [x] Rename functions run_skew() to ohlc_skew(), run_returns() to ohlc_returns(), run_sharpe() to ohlc_sharpe() and run_variance() to ohlc_variance()

+ [x] Update the functions run_var() and run_covar() - subtract the means from returns

+ [x] Create function run_var_ohlc() to calculate the running OHLC variance using running formula - adapt from ohlc_variance()

+ [x] Create function run_reg() - adapt from run_zscores()

+ [x] Remove volat argument in functions sim_ou(), sim_schwartz(), and sim_df() 

+ [x] In functions sim_df() and sim_schwartz() add argument init_price

+ [x] Create function sim_df() to simulate a Dickey-Fuller process

+ [x] Fix the regularization in calc_inv(): Check for zeros in the singular values svd_val to remove the zero singular values
Use the tolerance argument eigen_thresh.  If svd_val is less than eigen_thresh then remove it by adjusting eigen_max.

+ [x] In function back_test(), add the decay factor lambda for averaging the portfolio weights
This is equivalent to extending the holding period beyond the rebalancing period.

+ [x] Rename the argument "design" to "predictor"

+ [x] In function run_zscores() - de-mean the zscores when scaling them - introduce Boolean argument

+ [x] Fix function calc_var_ag() so that it works for remainder=0

+ [x] Update function sim_ou() - add initial equity price and return the equity price - not the returns

+ [x] Create function calc_cvar() for calculating the Value at Risk (VaR) and conditional VaR (CVaR) in R code

+ [x] Modify function sim_garch() so that it interprets the innovations as either standard random numbers or as historical returns

+ [x] Change calls from HighFreq::roll_var(method="quantile") to HighFreq::roll_var(method="nonparametric")

+ [x] Explain why TTR::runMAD() is much faster than HighFreq::roll_var(method="quantile")
Answer: Because HighFreq::roll_var(method="quantile") is not MAD - use method="nonparametric" instead.
HighFreq::roll_var(method="nonparametric") is slightly faster than TTR::runMAD().

+ [x] Create function lik_garch() to calculate the GARCH log-likelihood

+ [x] Update sim_arima() to accept matrix not vector - rename sim_arima() to sim_ar()

+ [x] Update sim_garch(), sim_ou(), and sim_schwartz() to accept matrix not vector
Add formulas to the documentation.

+ [x] Replace call-by-name syntax in C++ code

+ [x] Modify run_zscore() to allow multivariate regression
Rename to run_zscores()
Split tseries argument into response and design arguments, with design containing multiple columns of returns data.

+ [x] Create functions for calculating rolling aggregations of streaming data using a recursive filter with a lambda decay factor, instead of a convolution filter over a look-back interval
run_mean(), run_var(), run_covar(), run_zscore(), run_max(), run_min()

+ [x] Create function roll_sumep() for calculating the rolling sums at the end points

+ [x] Create function calc_var_ag() for calculating the variance of returns aggregated over end points

+ [x] Create function calc_hurst() for calculating the Hurst exponent from the ratios of variance of aggregated returns

+ [x] Create function calc_var_ohlc_ag() for calculating the variance of OHLC prices aggregated over end points

+ [x] Create function calc_hurst_ohlc() for calculating the Hurst exponent from the rescaled range of OHLC prices

+ [x] Replace the passing of large data by value with passing by reference (pointer) to improve performance (restore passing by reference which was removed)

+ [x] Add vignette and automatically build vignette  

+ [x] Create function roll_mean() for the rolling calc_mean() the centrality (location) estimator (first moment) using RcppArmadillo

+ [x] In functions roll_vec() and roll_vecw() convert arguments from arma::vec to arma::mat

+ [x] Modify function diff_it() to handle negative lags

+ [x] Modify function diff_it() to pad with zeros as in rutils::diff_it()

+ [x] In functions diff_vec() and diff_it(), rename argument padd to pad_zeros, as in lag_it()

+ [x] Modify function calc_inv() so it calculates the regularized inverse of a matrix, not the inverse of its covariance matrix

+ [x] Modify functions calc_reg() and roll_reg() to add method for regularized regression

+ [x] Create function calc_mean() for the centrality (location) estimator (first moment) using RcppArmadillo: mean, median, Hodges-Lehmann, and other unimodal robust estimators

+ [x] Create function roll_fun() to roll the functions calc_var(), calc_skew() and calc_kurtosis()

+ [x] Modify the functions which depend on calc_endpoints(): roll_reg(), roll_var(), roll_var_ohlc(), roll_skew(), roll_kurtosis(), roll_zscores()
Add arguments end_p and start_p and keep arguments step, stu_b, and look_back.
Add code to use end_p if it's non-zero, else to calculate end points from step, stu_b, and look_back.
Follow example of roll_wsum().

+ [x] Remove underscores from function arguments: rename stu_b to stub, oh_lc, weight_s, re_turns, se_ries, end_p, start_p

+ [x] In function calc_endpoints() add stub argument and remove argument front
The prototype is in test_temp.cpp

+ [x] Create function calc_reg() for performing different types of regressions
It should return a vector of coefficients, tvals, and zscore.
It's already partially implemented in C:/Develop/R/Rcpp/roll_reg.cpp

+ [x] Create function roll_reg() for performing rolling PCA and robust regressions
It should loop over end points using calc_endpoints() and calc_startpoints().
It should return a matrix of coefficients, tvals, and zscores.

+ [x] Update functions kurtosis_type() and calc_kurtosis() with actual kurtosis methods.

+ [x] Create function roll_kurtosis() for the rolling kurtosis estimator (fourth moment) using RcppArmadillo
It's already copied from C:/Develop/R/Rcpp/roll_kurtosis.cpp

+ [x] Create a function called roll_skew() for the rolling skewness estimator (third moment) using RcppArmadillo: include robust estimators
It's already implemented in C:/Develop/R/Rcpp/roll_skew.cpp

+ [x] In all the calc_* functions, return zero if number of rows is small

+ [x] Modify function roll_var() to calculate the rolling variance, MAD, and other robust estimators - add parameter "method" similar to calc_var() 

+ [x] Merge function calc_mad() into calc_var() - add parameter "method" to calc_var()

+ [x] In roll_wsum(), fix the naming conflict with the end_p argument, by declaring an internal Armadillo variable end_parma

+ [x] Fill new vectors and matrices with zeros using fill::zeros

+ [x] Rename parameter calc_method to method

+ [x] Create functions sim_ou() and sim_schwartz() to simulate the Ornstein-Uhlenbeck process and the Schwartz process.

+ [x] Rename argument t_series to se_ries

+ [x] Rename roll_sum() to roll_wsum()

+ [x] Create function roll_sum() for calculating a simple rolling sum over the columns of a matrix, without weighting or end points

+ [x] Modify function calc_weights(): 
Rename model_type == "rank" to model_type == "rank_sharpe"
Add model_type == "rank" for ranking the re_turns directly.

+ [x] Modify functions back_test() and calc_weights(): rename argument typ_e to model_type

+ [x] Create functions calc_mad(), calc_skew(), and calc_skewnp() to calculate the Median Absolute Deviation, the skewness, and the nonparametric skewness
Calculate the nonparametric skewness estimator using the quantiles: skewness = (quartile_75 - median) - (median - quartile_25)

+ [x] Create a function called roll_count() using RcppArmadillo which reproduces roll_countr() in scratch.R
roll_count() is already in lm_arma.cpp.
roll_count() should count the number of consecutive TRUE elements, and reset to zero after every FALSE element.

+ [x] Rename roll_sum() to roll_vec(), and roll_wsum() to roll_vecw()

+ [x] Modify the old function roll_sum() so that it accepts matrix argument and calculates the rolling sum over the columns of a matrix
Modify function roll_sum() to use arma::cumsum() and diff_it(), instead of explicit loop.
Function roll_sum() aggregates returns to a lower periodicity, similar to roll_ohlc().
If weight_s argument is not NULL, then perform weighted sum using convolution and function arma::conv2().
It would then replicate functions roll_wsum(), roll_conv(), and roll_conv_ref().
Pass in parameters end_points and weight_s with default NULL values, using the syntax:
Rcpp::Nullable<Rcpp::IntegerVector> end_points = R_NilValue
https://stackoverflow.com/questions/34205925/default-null-parameter-rcpp

+ [x] Modify function diff_it() to pad with initial (warmup) period

+ [x] Modify functions lag_vec() and lag_it() to add parameter pad_zeros
Add Boolean argument pad_zeros with default TRUE.
Modify the padding of leading or trailing values in the functions lag_it() and lag_vec()
If pad_zeros is TRUE then pad the leading or trailing values with zeros, else pad with leading or trailing row.
The returns data should be padded with zeros, not the first or last element of the input vector.
The prices should be padded with the first or last element of the input vector, not with zeros.

+ [x] Rename the R function roll_moment() to roll_stats()

+ [x] Rename the R function agg_regate() to agg_stats_r(), and parameter mo_ment to calc_bars

+ [x] Add to file README.Rmd overview of function taxonomy
The functions run_* aggregate individual rows of TAQ or OHLC data into single numbers, and they transform multiple column of TAQ or OHLC data into column vectors
The functions calc_* aggregate columnar data into a single number.
The functions roll_* perform loops over the rows of columnar data, and they apply the functions calc_* to subsets of the data over look-back intervals.

+ [x] Modify the functions roll_var() and roll_var_ohlc() to perform calculations over end points if ste_p argument is passed in

+ [x] Modify the function agg_ohlc() so it can accept either one or two columns of data (second column for volume), or four or five columns of OHLC data

+ [x] Rename the function to_period() to roll_ohlc()

+ [x] Create function calc_startpoints() as a lag of end points (unsigned integers)

+ [x] Create a function called calc_endpoints() to calculate the end points, similar to rutils::calc_endpoints()

+ [x] Create the functions called agg_ohlc() and to_period() for aggregating an OHLC time series to lower periodicity, similar to xts::to.period()

+ [x] Modify the functions diff_it() and diff_vec() so they don't use arma::diff(), because it doesn't apply lags greater than one

+ [x] In function calc_weights() scale the weights so that the resulting portfolio has a volatility of 1% - make this a parameter

+ [x] In function calc_inv() add option to regularize the inverse by discarding small eigenvalues less than a tolerance level: use arma::pinv()
This is because the best choice for max_eigen can change in a rolling calculation, so it's better to introduce a tolerance cutoff.

+ [x] In function calc_weights() add option for quantile weights, with argument "typ_e == quantile" and add argument "quan_tile == 0.1": with weights equal to 1 for top quantile, -1 for bottom quantile, and otherwise 0.

+ [x] Change license from GPL to MPL, similar to package data.table.

+ [x] Rename roll_conv() to roll_conv_ref(), and modify roll_conv() so it doesn't copy over the input argument mat_rix.
Copying over the input argument mat_rix causes snooping data leak in backtest.

+ [x] Test the function roll_conv() to determine if it applies convolution only over past values.

+ [x] Rename function roll_wsum() to roll_conv(), because it replicates convolution - no!
The function roll_wsum() is for vectors and is not the same as roll_conv() which is for matrices.

+ [x] Create RcppArmadillo function calc_ranks() for calculating the ranks of the elements of a vector.

+ [x] Remove the existing function roll_variance() in R, and rewrite it in RcppArmadillo as roll_var()

+ [x] Compare the speed of performing RcppArmadillo loops over columns versus subviews of rows: loops over rows are slightly faster than over columns

+ [x] Create a function called roll_var_ohlc() in RcppArmadillo which calculates the rolling variance over a time series of OHLC prices

+ [x] Rename roll_var() to roll_var_vec() and update its documentation

+ [x] Create a function called roll_var() in RcppArmadillo which calculates the rolling dispersion estimator (variance - second moment) over a matrix using RcppArmadillo

+ [x] Create the functions called diff_vec() and diff_it() (for matrices), similar to rutils::diff_it(), using the RcppArmadillo function arma::diff()

+ [x] Create a function called calc_var_ohlc() in RcppArmadillo, which calculates the variance of a time series of OHLC prices, similar to the function calc_var_ohlc_r()

+ [x] Rename the existing R function calc_variance() to calc_var_ohlc_r(), and refactor the code to make it faster and more readable

+ [x] Create a function called lag_it() using RcppArmadillo which lags a column vector or a matrix, similar to rutils::lag_it()

+ [x] Create a function called lag_vec() using RcppArmadillo which lags a vector

+ [x] Create a function called calc_var() in RcppArmadillo to calculate the variance of a matrix

+ [x] Create a function called calc_var_vec() in RcppArmadillo to calculate the variance of a vector

+ [x] Add RcppArmadillo function mult_vec_mat(), which multiplies the columns or rows of a matrix times a vector, element-wise.

+ [x] In back_test() fix bid_offer bug: should be subtracted from PnL not added  

+ [x] In function calc_weights() add additional option for rank momentum, with argument "typ_e == rank": rank weights using trailing Sharpe

+ [x] In function back_test() add argument co_eff to multiply the weights.

+ [x] In function back_test() add transaction costs: remember previous weights and subtract current weights from previous weights
Add argument bid_offer the bid-offer spread.

+ [x] Rename function roll_portf() to back_test()

+ [x] Add header to HighFreq.R file to fix NAMESPACE issue:
#' @useDynLib HighFreq
#' @importFrom Rcpp evalCpp
#' @exportPattern "^[[:alpha:]]+"

+ [x] Create a function called roll_conv() for calculating the convolutions of the matrix columns

+ [x] In function calc_weights() add additional options for the typ_e argument: quadratic weights constraint (highest principal component)

+ [x] In function calc_weights() modify weight_s scaling: scale the weights to match the volatility of mean returns

+ [x] In function calc_weights() add argument called typ_e (with default value "max_sharpe"), which specifies the objective function of portfolio optimization used for calculating the weights

+ [x] Replace zoo::na.locf() with xts:::na.locf.xts()

+ [x] Remove RcppParallel dependency from DESCRIPTION

+ [x] Add ByteCompile: TRUE to the DESCRIPTION file

+ [x] Generate man files for Rcpp functions
Select the "Document" item in build menu or run R command devtools::document()

+ [x] Modify DESCRIPTION file
Added: Encoding: UTF-8
Removed from Imports: caTools, lubridate, TTR, 

+ [x] Fix build error about RcppExports.R.

+ [x] Modify functional roll_apply()
Change endpoints calculation: define look_backs as a list of numeric vectors.
Calculate aggregations using lapply() loop over the look_backs, instead of sapply().
Add option to coerce output into xts series.

+ [x] Create functional roll_backtest() similar to roll_apply(), but accepting two functions as arguments

+ [x] Replace argument "lag" with "lagg" (to avoid confusing it with stats function lag())  

+ [x] Replace calls to is.vector(in_put) with is.null(dim(in_put))

+ [x] Replace "win_dow" with "look_back"

+ [x] Fix bug in function run_variance() for calc_method="yang_zhang": remove win_dow from formula for co_eff.

+ [x] Replace xts::.subset_xts() with brackets operator []

+ [x] Add volatility, drift rate, and convexity correction to functions random_taq() and random_ohlc()  

+ [x] Fix bug in random_ohlc(): transform to normal distribution before sampling from rows of OHLC (otherwise it produces negative prices)  

+ [x] Move functions adjust_ohlc(), to_period() and get_symbols() from HighFreq to rutils  

+ [x] Remove and/or adjust time scaling factors in run_variance(), run_skew(), and random_ohlc()

+ [x] Rename functions *_OHLC and *_TAQ to *_ohlc and *_taq

+ [x] Create function adjust_ohlc() that adjusts OHLC data, similar to quantmod::adjustOHLC()  

+ [x] Create function get_symbols() that downloads time series data, similar to quantmod::getSymbols()  

+ [x] Replace quantmod extractor functions Op(), Hi(), Lo(), Cl(), Vo() with direct subsetting: oh_lc[, 3] Instead of Lo(oh_lc)

+ [x] Modify function run_returns(): add argument  

+ [x] Update README and web page  

+ [x] Add vignettes directory and create multiple vignettes using files README and demo_HighFreq.R  

+ [x] Create function random_TAQ() that returns random TAQ data

+ [x] Create function random_OHLC()
returns random OHLC data used for testing for data snooping (look ahead bias) and benchmarking
Either create synthetic data or sample from real data.  
Run random data through model to test if there is data snooping.  

+ [x] Add a single day of TAQ data for SPY to hf_data.RData file  

+ [x] Add TLT, VXX, and SPY to hf_data.RData file  

+ [x] Add lubridate to Imports in DESCRIPTION file  

+ [x] Create function roll_sharpe()

+ [x] Modify functions run_variance() and run_skew() to scale their outputs by the time differences, similar to run_returns()  

+ [x] Create a function called sim_arima() in RcppArmadillo which replicates the function stats::filter() with method="recursive"
Adapt code from /Users/jerzy/Develop/lecture_slides/scripts/sim_arima.cpp

+ [x] Add sim_* functions using RcppArmadillo: sim_arima(), sim_garch()

+ [x] Add calc_* functions using RcppArmadillo: calc_eigen(), calc_inv(), calc_scaled(), calc_lm(), calc_weights()

+ [x] Add roll_* functions using RcppArmadillo: roll_wsum(), roll_zscores(), roll_scale(), roll_portf()

+ [x] Create function remove_jumps() to remove overnight close-to-open jumps from OHLC (?)  

+ [x] Replace na.locf() with rutils::na_locf()

+ [x] Rename function extreme_values() to which_extreme()  

+ [x] Rename function price_jumps() to which_jumps()  

+ [x] Add arguments lag and sca_le to function run_returns()

+ [x] In functions calc_variance(), run_variance(), roll_variance(), and run_skew() don't perform log(oh_lc) - that can be done externally

+ [x] Replace calls to lag_xts() with lag_it()

+ [x] Replace calls to diff_xts() with diff_it()

+ [x] Add argument sca_le to functions run_variance() and roll_variance()

+ [x] Fix functions roll_hurst() and roll_sharpe() so they call roll_variance() instead of run_variance()  
in roll_hurst() replace TTR::runMax() with RcppRoll::roll_max()

+ [x] Remove arguments off_set and roll_end_points from function roll_hurst()

+ [x] Create function calc_variance() which calculates a single variance number from the output of run_variance()

+ [x] Create function roll_variance() that replicates TTR::volatility()  
Clone run_variance(), but modify it by subtracting the means
Use functions RcppRoll::roll_var() and rutils::roll_sum()
Add correct coefficient co_eff for yang_zhang method

+ [x] Modify comments for function run_variance() to explain that it's only an indicator, not an estimator

+ [x] Modify function run_returns(): remove time scaling, calculate percentage returns  

+ [x] Apply Hampel median filter to scrub data: that's what HighFreq does already  
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
update the documentation to reflect that HighFreq already uses Hampel median filter

+ [x] Create functional roll_apply(), similar to xts:::rollapply.xts() and xts::period.apply()  
use apply_rolling() from utilLib

+ [x] Rename function roll_agg() to roll_moment(), and its argument esti_mator to mo_ment  

+ [x] Rename functions calc_returns(), vari_ance(), skew_ohlc(), sharpe_ohlc() to run_returns(), run_variance(), run_skew(), run_sharpe()  

+ [x] Rename function v_wap() to roll_vwap()  

+ [x] Modify function roll_hurst() using TTR::runMax()  

+ [x] Rename function hurst_ohlc() to sharpe_ohlc()  

+ [x] Rename and modify function calc_rets() to calc_returns(): 
return single column with name "SPY.returns"
will break save_rets() and save_rets_ohlc()

+ [x] Modify function v_wap() to accept argument x_ts  

+ [x] Remove .Rproj.user directory from GitHub repository
steps:
- open Windows PowerShell from GitHub Desktop
- run: git filter-branch --tree-filter 'rm -f -R .Rproj.user' HEAD
- run: git push origin master -f
http://stackoverflow.com/questions/32228841/github-gitignore-adds-folder-previously-not-on-gitignore

+ [x] Create project website for HighFreq on GitHub Pages using R Markdown  

+ [x] Rename README.md to .Rmd and add more detailed description similar this to README.md:  
https://github.com/RcppCore/rcpp-gallery/blob/gh-pages/src/2016-05-27-HRP.Rmd
use rmarkdown templates
https://rud.is/b/2016/02/04/alternate-r-markdown-templates/
https://github.com/hrbrmstr/markdowntemplates
http://svmiller.com/blog/2016/02/svm-r-markdown-manuscript/

+ [x] Modify function hurst_ohlc() to calculate (C-O)/(H-L)

+ [x] Create function roll_hurst() for rolling Hurst exponent, similar to roll_sum()  
Detrended fluctuation analysis - is it like variance ratios?
Hurst analysis is related to Detrended fluctuation analysis:
https://en.wikipedia.org/wiki/Detrended_fluctuation_analysis
HurstIndex() from PerformanceAnalytics is wrong because it uses range of returns, instead of range of cumulative returns!
variance ratio test
http://quant.stackexchange.com/questions/7666/using-variance-ratios-to-test-for-mean-reversion

+ [x] Move function roll_sum() from HighFreq to rutils

+ [x] Add to function season_ality() in_dex argument

+ [x] Perform bootstrap estimation of standard errors for all the methods in function vari_ance()  
benchmark to random OHLC

+ [x] Add to function vari_ance() the methods "garman.klass_yz" and "yang.zhang"  

+ [x] Modify functions vari_ance() to accomodate case when open price isn't equal to previous close price - methods "garman.klass_yz" and "yang.zhang"  

+ [x] Rename function vol_ohlc() to vari_ance()

+ [x] Create function to_period()  

+ [x] Rename argument agg_fun to esti_mator, in functions agg_regate() and roll_agg()  

+ [x] Remove calc_method argument from agg_regate() and roll_agg() - instead use "..." argument

+ [x] Rename agg_ohlc and roll_agg_ohlc() to agg_regate() and roll_agg()  

+ [x] Dereference all external functions using "::", i.e. rutils::na_me()

+ [x] Add @export to roxygen code  

+ [x] Convert all code from nrow() and ncol() to NROW() and NCOL()  

+ [x] Replace strsplit(colnames(ohlc)[1], split="[.]")[[1]][1] With rutils::na_me(ohlc)  

+ [x] Fix roxygen .Rd documentation file building error - name at end of hf_data.R file was wrong - should be the names of objects, i.e. "SPY", "sym_bol", not the file name  

+ [x] Create data documention  

+ [x] Rename moment_ohlc() and roll_moment_ohlc() to agg_ohlc and roll_agg_ohlc()
mom_fun to agg_fun

+ [x] Create function hurst_ohlc() for calculating Hurst exponent from OHLC data
OHLC data naturally lends itself to Hurst analysis: ratio of (H-L)/(C-O)

+ [x] In moment_ohlc() and roll_moment_ohlc() removed log of ohlc
moment_ohlc() and roll_moment_ohlc() should pass ohlc to skew_ohlc() and vol_ohlc(), etc., not log ohlc

+ [x] Modify skew_ohlc() and vol_ohlc() to accept ohlc, not log ohlc, and to apply log internally

+ [x] Include rutil package 

+ [x] Create function for performing daily, weekly, and monthly seasonality aggregations

+ [x] Rename functions run_* to roll_*

+ [x] Rename save_OHLC() to save_scrub_agg()

+ [x] In save_rets_OHLC() update documentation

+ [x] In save_OHLC() combine sapply loops into one

+ [x] In save_OHLC() and save_rets() pass scrub params to scrub_agg

+ [x] Add timezone to argument list

+ [x] Create function save_TAQ()
	saves scrubbed TAQ and/or OHLC data in daily files
	similar to save_OHLC, but doesn't aggregate and saves into multiple files

+ [x] Create function calc_rets()
	calculate returns of time series

created function save_rets() (similar to save_OHLC): 
	scrub and aggregate data, calculate returns, and save them

created function save_rets_OHLC()
	similar to save_rets, but assumes clean OHLC input data
	- no scrubbing or aggregation


### Tasks deprecated

+ [ ] Switch terms around in running formulas?
t = (1  )pt + t1
t = t1 + (1  )pt

+ [ ] Pass a function to a function using Numerical Template Toolbox (NT2) - Nobody uses NT2
http://gallery.rcpp.org/articles/rcppnt2-introduction/

+ [ ] Rename roll_moment(): it doesn't calculate moments, because it doesn't subtract the rolling means
Deprecate function roll_moment() because it's similar to roll_vwap() ?
Update the description documentation of roll_moment()

+ [ ] Rewrite all weighted averages using convolution and function arma::conv2() - it's actually quite slow

+ [ ] In function calc_weights() don't calculate the mean of returns and the covariance of returns, but instead pass them in as arguments?
But then weight scaling has to be performed outside calc_weights().

+ [ ] Rename miscellaneous functions as do*() - No
For example, rename function diff_it() as do_diff()

+ [ ] Modify function calc_endpoints(): call function xts::endpoints() if argument is an xts series ?

+ [ ] Rename the variable weights to weightv ?

+ [ ] Remove unnecessary pointer "&" and "const" attributes from input arguments - No!
Passing pointers as arguments into functions increases their speed by 30% or more for very large vectors with a million or more elements.

+ [ ] In function roll_wsum() add argument start_p - it's not needed because the length of weights determines the start points

+ [ ] Rewrite the function roll_zscores() to make it similar to roll_var(): create function calc_zscores() and loop over end points using calc_endpoints() and calc_startpoints()

+ [ ] Create a function called roll_stdev() for the rolling standard deviation, MAD, and other unimodal robust estimators

+ [ ] Convert roll_* functions to RcppRoll ?  No, because RcppArmadillo and Rcpp are better

+ [ ] Rename the functions run_* to to cast_* apply_* transform_* accumulate_*?

+ [ ] Modify function run_returns() to perform sapply() if argument has multiple columns ?

+ [ ] Remove extra increment of 1 in start_points index in roll_apply() - no, because otherwise it would create overlaps when aggregating returns (for example)  
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))]
instead of:
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))] + (NROW(oh_lc) > (len_gth+1))

+ [ ] Modify "close" method in function run_variance() by averaging open and close prices - no creates a bias underestimates variance  

+ [ ] Subtract mean in functions run_variance() and run_skew() - no  

+ [ ] Convert function season_ality() to use split.xts() (?)  

+ [ ] Replace caTools with TTR functions (?)  
Only runquantile() is called from caTools.
But not easy to replace runquantile(), because no equivalent TTR function.
Would require rewriting extreme_values() and price_jumps(), and then benchmarking.

+ [ ] Use .subset_xts() (?)

+ [ ] Rename save_rets_OHLC to rets_OHLC (?)  

+ [ ] Calculate volume-weighted moments and compare them to standard moments
add volume-weighting to vol_ohlc() and skew_ohlc()


### Commits

# commit 05-18-16
added rutils to depends in DESCRIPTION
moved do_call_rbind to rutils

# commit 05-17-16 bis
Added function season_ality()

# commit 05-17-16
Renamed functions from run_* to roll_*

# commit 11-03-15
fixed function v_wap() from Ad() to Cl()

# commit 10-03-15
added functions run_sum() and v_wap()

# commit 05-29-15
Finished R/Finance_2015 presentation

# commit 03-27-15
added timezone to argument list
updated functions: calc_rets, save_rets

# commit 03-16-15
added functions: calc_rets, save_rets, save_TAQ
updated functions: save_OHLC, scrub_TAQ
added "data" folder
updated roxygen documentation


# commit 03-01-15
added roxygen documentation

created functions:
save_OHLC
scrub_TAQ

scrub_agg:
change time zone
to trading hours
merge duplicate time stamps using make.index.unique - no
remove duplicate time stamps using duplicated
calculate mid price?
NA omit mid price
convert NA volumes to zero
replace NA trade prices with mid prices
scrub on mid price:
	bid-offer spread
	if bid-offer spread too wide then use trade price?
	hairlines


in save_OHLC
add save dir
coerce using quantmod.OHLC? - no

create function save_TAQ:
save scrubbed daily TAQ data to daily files
use quantmod standard headers - quantmod naming conventions

create function similar to getSymbols (?):
load and rbind TAQ data (without scrubbing or aggregating)


# commit 02-17-15
renamed many functions and variables
added roxygen comments
added demo folder and files
edited README
updated HighFreq-package.Rd



