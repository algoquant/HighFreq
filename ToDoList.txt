############
### ToDo list for package HighFreq: high frequency data scrubbing

### Scripts for package building

## Steps for installing package called my_package, containing Rcpp code:
1. Create empty package directory with Rcpp::Rcpp.package.skeleton()
2. In the R directory create a file called my_package.R and add the header:
#' @useDynLib my_package
#' @importFrom Rcpp evalCpp
#' @exportPattern "^[[:alpha:]]+"
NULL
Add your R functions below the header.
3. Finally, from the Build menu run Clean and rebuild.


## How to update the NAMESPACE file after adding a new function
Edit the NAMESPACE file and add a line to export the new function new_func(): 
export(new_func)


## Steps to fix the NAMESPACE file after adding a new function - sometimes produces a bad NAMESPACE file
1. In RStudio from Build menu run Document - usually produces a bad NAMESPACE file
2. Edit the NAMESPACE file again and remove all lines that don't contain export()
3. Move to top of NAMESPACE file the lines:
useDynLib(HighFreq)
importFrom(Rcpp, evalCpp)


## Build scripts:

# Install package from source on local drive
install.packages(pkgs="C:/Develop/R/HighFreq", repos=NULL, type="source")
# Install package from source on local drive using R CMD
R CMD INSTALL C:\Develop\R\HighFreq
# Install NPE package from local drive
setwd("C:/Develop/R/HighFreq")
install.packages(pkgs="C:/Develop/R/HighFreq", repos=NULL, type="source")
# Install package from Github
devtools::install_github(repo="algoquant/HighFreq", force=TRUE)
# Document the package - run R command
devtools::document()
# Build vignette package reference manual from *.Rd files
system("R CMD Rd2pdf C:/Develop/R/HighFreq")
cd C:\Develop\R\HighFreq\vignettes
R CMD Rd2pdf C:\Develop\R\HighFreq\



### Comments

# When performing a rolling calculation, it's better to apply a single lag to a time series outside the loop instead of lagging it inside at each end point

# Passing pointers as arguments into functions increases their speed by 30% or more for very large vectors with a million or more elements.  But it can make it harder to pass in arguments when calling them from inside other functions.  The solution is to avoid nesting function calls, and instead create intermediate variables, and pass them into functions.  Passing in pointers also allows using const arguments so that they can't be modified inside the function.

# Volume weighted volatility is higher than simple average volatility because volumes are higher when volatility is higher. 

# The yang_zhang method has the lowest standard error assuming normal distribution, but not necessarily for fat-tailed distributions.
In addition, the yang_zhang method has lower bias caused by finite sampling.
The rogers_satchell method has the biggest bias caused by finite sampling and opening price jumps, and seriously underestimates the variance.

# Theoretically, the Yang-Zhang (YZ) and Garman-Klass-Yang-Zhang (GKYZ) range variance estimators are unbiased and have up to seven times smaller standard errors than the standard close-to-close estimator.  But in practice, prices are not observed continuously, so the price range is underestimated, and so is the variance when using the YZ and GKYZ range estimators.  Therefore in practice the YZ and GKYZ range estimators are biased (underestimate volatility).  In addition, the standard errors are reduced less than by the theoretical amount, for the same reason. 

# Using the average of open and close prices in the standard variance estimator (instead of just the close prices) doesn't reduce the standard error.

# High frequency data has three tenor horizons: daily (daily or lower frequency of data), intraday (secondly to daily frequency of data), and sub-second tenor horizons (sub-secondly or higher frequency of data).
At the sub-second tenor horizon, returns are dominated by noise and the bid-ask bounce.
Returns are dominated in their scale by the volatility, and they have no discernable trend.
At the sub-second horizon technical indicators are meaningless, and instead traders analyze the order book for clues about future returns.
At the intraday tenor horizon volatility, skew, and kurtosis are high, and mean-reversion dominates trending.
Technical indicators based on past returns and trading volumes can offer clues about future returns.
At the daily tenor horizon skew and kurtosis are small, and trending dominates mean-reversion.

# Calculating returns on 1-second bars doesn't make sense for two reasons: 
First, because the changes in price are very small, comparable to the precision of prices (number of significant digits).
As a result, price changes on 1-second bars are either zero or low multiples of the precision. 
Second, the 1-second bar prices bounce randomly between static bid and ask prices (the bid-ask bounce).  
Therefore 1-second bar returns carry almost no information.


### Tasks to-do

+ [ ] Create functions for calculating rolling aggregations of streaming data using a recursive filter with a lambda decay factor, instead of a convolution filter over a look-back interval
run_mean(), run_var(), run_maxmin(), run_covar(), run_zscore(), 

+ [x] Create function calc_var_ag() for the calculating variance of returns aggregated over end points

+ [x] Create function calc_hurst() for calculating the Hurst exponent from the ratios of variance of aggregated returns

+ [ ] Create function calc_var_ohlc_ag() for the calculating variance of OHLC prices aggregated over end points

+ [ ] Create function calc_hurst_ohlc() for calculating the Hurst exponent from the rescaled range of OHLC prices

+ [ ] Create functions roll_max() and roll_min()

+ [ ] Create function adf_test() to calculate the ADF coefficients using matrix algebra

+ [ ] Modify functions calc_weights() and back_test() to perform rolling portfolio optimization in the simplified case of orthogonal Forecastable Component Analysis (FCA)

+ [ ] Modify function calc_weights(): 
Rename model_type == "rank" to model_type == "rank_sharpe"
Add model_type == "rank" for ranking the re_turns directly.

+ [ ] Modify function calc_endpoints(): call function xts::endpoints() if argument is an xts series

+ [ ] Remove Rcpp features like Rcpp::Nullable to make the code closer to pure C++
https://stackoverflow.com/questions/2537942/nullable-values-in-c
https://en.cppreference.com/w/cpp/named_req/NullablePointer

+ [ ] In function calc_kurtosis() update the method nonparametric

+ [ ] In function roll_reg() add option to perform rolling predictions using the regressions

+ [ ] In function calc_reg() add additional types of regressions: robust Theil-Sen regression, rank regression, quantile regression, PCA regression with shrinkage, etc.
It should calculate Pearson, Spearman, and Kendall correlations.
It should return a named vector of coefficients, tvals, and zscore.

+ [ ] In function calc_lm() add Boolean parameter to add intercept column to explanatory matrix

+ [ ] In function calc_var() add robust dispersion estimators

+ [ ] In function roll_var() use moment update formulas from package fromo: Pebay Fast Moments.pdf
Calculate rolling variance efficiently (used by package fromo): https://www.johndcook.com/blog/standard_deviation/

+ [ ] In function roll_var() calculate the rolling variance from the rolling sums of returns and the rolling sums of squared returns
This avoids calling calc_var() in loop.

+ [ ] Explain why TTR::runMAD() is much faster than HighFreq::roll_var(method="quantile")
ma_d <- TTR::runMAD(clos_e, n=look_back)
ma_d <- HighFreq::roll_var(clos_e, look_back=look_back, method="quantile")

+ [ ] Enhance the function calc_var() to calculate the variance for overlapping aggregated returns: the variance of returns aggregated over k time periods - the prototype is in test_temp.cpp

+ [ ] Create aggregation function agg_regate() similar to roll_ohlc(), which aggregates returns, prices, etc. to time series with lower periodicity.
Worker agg_ohlc()

+ [ ] Rewrite all weighted averages using convolution and function arma::conv2()

+ [ ] Modify rolling Theil-Sen function to return a column of the MAD of pair slope estimates

+ [ ] Deprecate function roll_conv_ref() ?
Does it actually calculate by reference?

+ [ ] Combine functions sim_ou() and sim_schwartz() into a single function?

+ [ ] Create function calc_covar() to calculate a nonparametric (robust) covariance matrix
Calculate the MAD covariance - the covariance based on the median, analogous to the MAD Median Absolute Deviation.
Several possible methods are: 
The covariance is equal to the difference between the variance of the sum minus the variance of the difference: 
cov = (VAR(r1+r2) - VAR(r1-r2))/4
Quantile estimator: weighted sums of the median and higher quantiles of asset returns.
Hodges-Lehmann estimator: 

+ [ ] Create function calc_alpha() to calculate the performance of an asset relative to an index. 
calc_alpha() should implement several different methods, with the default being Jensen's alpha. 
One robust method should be the Wilcoxon W statistic.
Another robust method should be the Kruskal-Wallis H statistic as follows:
Combine the given asset returns with the index returns into a single vector.
Rank the vector of combined returns.
Calculate the H statistic as the difference between the sum of the ranks of the asset returns minus the sum of the ranks of the S&P500 returns.
The H statistic is reminiscent of the difference between the mean asset returns minus the mean S&P500 returns.

+ [ ] Create function calc_ret_stats() for calculating aggregations (statistics) over a vector of returns
Examples of statistics are the mean, median, Sharpe ratio (t-value), Wilcoxon statistic, etc.

+ [ ] Modify function back_test() so it returns a matrix of strategy returns and positions

+ [ ] Modify back_test() add parameter for lagging the weights - for applying the weights with an extra lag

+ [ ] Convert all time loops to loops over the end points, using calc_endpoints() and calc_startpoints()

+ [ ] Create a function called roll_quantile() for the rolling quantile

+ [ ] Create function calc_quantile() to calculate or update the quantile of a vector of numbers
The value of the quantile can be updated based on the old quantile value and the new updated vector values.
If there are very few new vector values and if they're all far from the old quantile value, then the quantile may remain unchanged.
Apply it to the calculation or rolling quantiles.

+ [ ] Modify calc_weights() shrink the returns to a portfolio with weights proportional to the asset betas

+ [ ] Add roxygen2 options for inherited parameters - but doesn't wotk in Rcpp
Use the example roxygen code in R code:
//' @inheritParams which_extreme

+ [ ] Fix the inheritParams Roxygen2 option in HighFreq.cpp
After installing roxygen2:
devtools::install_github("r-lib/roxygen2")
These Roxygen2 options don't work
@inheritParams calc_var
@inherit calc_var return params
https://gallery.rcpp.org/articles/documenting-rcpp-packages
https://cran.r-project.org/web/packages/roxygen2/news/news.html
https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html#inheriting-documentation-from-other-topics
https://stackoverflow.com/questions/65739109/r-r6-inheritance-with-roxygen2-class-parentclass-is-not-exported-by-namespa

+ [ ] Add unit testing using testthat and devtools: create /tests directory

+ [ ] Create a function called get_fun() for dispatching functions in C++: it should accept a string with a function name and return a pointer to the function with that name

+ [ ] Create function roll_fun() that accepts a function pointer argument and rolls it over end points
Adapt function roll_var() or roll_skew().
Initial attempts show that it's a very difficult project because the calc_* functions have different arguments.
Use map:
http://www.cplusplus.com/forum/beginner/195580/
https://bytes.com/topic/c/answers/561361-string-convert-function-name
http://www.cplusplus.com/reference/map/map/

+ [ ] Modify function back_test() so it accepts a C++ prediction/forecasting function (functor, function pointer)  
https://stackoverflow.com/questions/7143120/convert-string-to-variable-name-or-variable-type
http://bytes.com/forum/thread656124.html

+ [ ] Pass a function pointer
https://gallery.rcpp.org/articles/passing-cpp-function-pointers/
https://en.wikipedia.org/wiki/Function_pointer#Example_in_C
test_xptr.cpp
xptr_drivers.R

+ [ ] Pass a function to a function using Numerical Template Toolbox (NT2)
http://gallery.rcpp.org/articles/rcppnt2-introduction/

+ [ ] Pass model function and its parameters into back_test() as a vector or a list
http://gallery.rcpp.org/articles/passing-cpp-function-pointers/
https://stackoverflow.com/questions/43616778/passing-user-created-c-functions-in-rcpp-as-arguments
https://stackoverflow.com/questions/51274385/calling-rcpp-function-with-xptr-and-function-only-xptr-case-works
https://stackoverflow.com/questions/50548060/generating-xptr-from-rcpp-function
https://stackoverflow.com/questions/49539341/rcpp-lost-on-how-to-utilize-rcppxptr-to-wrap-a-pointer

+ [ ] Pass parameters to function back_test() using parameter pack and dots or va_list argument to C++ functions
https://stackoverflow.com/questions/3530771/passing-variable-arguments-to-another-function-that-accepts-a-variable-argument
https://stackoverflow.com/questions/20901811/function-with-three-dots-argument
https://codesteps.com/2014/05/16/how-to-pass-variable-number-of-arguments-to-c-cpp-functions/
https://kevinushey.github.io/blog/2016/01/27/introduction-to-c++-variadic-templates/
https://stackoverflow.com/questions/24590946/passing-many-argumentes-by-ellipsis-in-rcpp
https://stackoverflow.com/questions/39792417/what-does-this-three-dots-means-in-c
https://vcpptips.wordpress.com/tag/three-dots-as-parameter/
https://xenakios.wordpress.com/2014/01/16/c11-the-three-dots-that-is-variadic-templates-part/
https://en.cppreference.com/w/cpp/language/parameter_pack
https://stackoverflow.com/questions/3351056/create-va-list-dynamically

+ [ ] Adapt STL code from test_stl.cpp

+ [ ] Convert some loops to STL iterators: iterators are pointers to vector and matrix elements
It may be simpler to use std::accumulate().
https://www.geeksforgeeks.org/iterators-c-stl/

+ [ ] Replace only some Rcpp syntax with Armadillo or Boost or STL
There are several advantages of using Rcpp::NumericVector instead of std::vector<double> :
NumericVector avoids deep copy of data between R and C++
NumericVector provides access to Sugar functions.
For example, if you replace NumericVector with std::vector<double> then you lose flexibility and need two copies of every function - one for integer and one for double.
cpp::NumericVector over std::vector<double>
https://stackoverflow.com/questions/41602024/should-i-prefer-rcppnumericvector-over-stdvector

+ [ ] Modify function roll_vwap() so that it calls RcppRoll::roll_sum() ? 

+ [ ] Convert function calls to roll functions from package RcppRoll to native Rcpp functions: roll_max() and roll_var()

+ [ ] Rename roll_moment(): it doesn't calculate moments, because it doesn't subtract the rolling means
Deprecate function roll_moment() because it's similar to roll_vwap() ?
Update the description documentation of roll_moment()

+ [ ] Perform rolling regressions over trading time - using a time-dependent look-back interval, so that the look-back interval always spans the same traded volume  
Inoue Rolling Regressions Time Series Bias Variance Tradeoff.pdf
Easley Volume Clock Trading Paradigm.pdf
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Modify roll_zscores() so it updates the previous regression, instead of performing a new regression at every point in time

+ [ ] Modify function calc_scaled() so it performs the calculation in place, without copying the matrix in memory ?
That may not always be correct, for example in the case of rolling calculations.

+ [ ] Create a function called na_locf()
// [[Rcpp::export]]
NumericVector na_locf(NumericVector x) {
  NumericVector output = Rcpp::clone(x);
  double lastNonNA = NA_REAL;
  int n = x.size();

  for (int i = 0; i < n; ++i)
  {
    double value = output[i];
    if (!ISNAN(value))
      lastNonNA = value;
    else
      output[i] = lastNonNA;
  }
  return output;
}
arma::uvec any_na_x(const NumericMatrix& x) {
  int n_rows_x = x.nrow();
  int n_cols_x = x.ncol();
  arma::uvec result(n_rows_x);
  
  for (int i = 0; i < n_rows_x; i++) {
    int any_na = 0;
    int j = 0;
    
    while ((any_na == 0) && (j < n_cols_x)) {
      if (std::isnan(x(i, j))) {
        any_na = 1;
      }
      j += 1;
    }
    result[i] = any_na;
  }
  return result;
}
arma::uvec any_na_xy(const NumericMatrix& x, const NumericMatrix& y) {
  int n_rows_xy = x.nrow();
  int n_cols_x = x.ncol();
  int n_cols_y = y.ncol();
  arma::uvec result(n_rows_xy);
  
  for (int i = 0; i < n_rows_xy; i++) {
    int any_na = 0;
    int j = 0;
    int k = 0;
    while ((any_na == 0) && (j < n_cols_x)) {
      if (std::isnan(x(i, j))) {
        any_na = 1;
      }
      j += 1;
    }
    while ((any_na == 0) && (k < n_cols_y)) {
      if (std::isnan(y(i, k))) {
        any_na = 1;
      }
      k += 1;
    }
    result[i] = any_na;
  }
  return result;
}

+ [ ] Create a function in RcppArmadillo which replicates the function zoo::na.fill(), and which replaces NA, NaN, and Inf values, but in place, without returning a value

+ [ ] Add functions for median and MAD in Rcpp
http://gallery.rcpp.org/articles/robust-estimators/

+ [ ] Apply STL algorithm function to perform find/which operation
http://adv-r.had.co.nz/Rcpp.html#stl

+ [ ] Add very fast RcppArmadillo functions: whi_ch(), cum_sum(), select_sub_mat()
http://arma.sourceforge.net/docs.html
https://stackoverflow.com/questions/23849354/equivalent-of-which-function-in-rcpp

+ [ ] Create new roll functions using RcppRoll::rollit() ?

+ [ ] Add to back_test() the simulation with limit orders

+ [ ] Remove all parallel code and references to parallel packages from HighFreq  

+ [ ] Create function predict_lm() which calculates the predicted out-of-sample values based on the coefficients from calc_lm()

+ [ ] Modify functional roll_backtest() so that it performs lapply() and returns a list of trade_func() outputs, containing the xts time series of out-of-sample returns   
trade_func() should return a list with at least two elements: time series and named vector of statistics (Sharpe, etc.)

+ [ ] Create functions roll() and run() in Rcpp - already done ?

+ [ ] Add to function random_ohlc(): simulate random non-normal OHLC prices from Heston model

+ [ ] Apply dynamic dispatch to create s single function to handle both vector and matrix arguments
https://gallery.rcpp.org/articles/dynamic-dispatch-for-sparse-matrices/
https://stackoverflow.com/questions/27466319/templated-matrix-in-rcpp
https://stackoverflow.com/questions/22513529/templated-function-for-sparse-and-dense-matrices-in-rcpparmadillo
https://stackoverflow.com/questions/45163887/how-can-i-use-a-c-function-template-in-r-via-rcpp

+ [ ] Fix bug in function random_ohlc() when sampling from rows of an input OHLC series (oh_lc not NULL): overnight returns are resampled into intraday periods, causing overestimation of variance.  
As a result, bootstrapped standard errors for Garman-Klass-Yang-Zhang and Yang-Zhang methods are too big.  
Possible fixes:
modify random_ohlc() so that it samples from secondly return data and aggregates to minutely OHLC data (does this solve the problem?) - save random minutely OHLC prices to file for future use  
modify random_ohlc() so that it samples from minutely return data scaled by time, and aggregates to minutely OHLC data

+ [ ] Bootstrap the range volatility estimators on random non-normal OHLC prices to check if indeed they have lowest standard error
use package meboot for maximum entropy bootstrap of time series ?
https://cran.r-project.org/web/packages/meboot/index.html

+ [ ] Create a function for calculating microprice  

+ [ ] Tell Joshua Ulrich that there's a bug in function TTR::volatility(), in the formula for the k coefficient in the Yang-Zhang estimator p.49
The correct formula is on p.7 of Yang OHLC Range Volatility Estimators.pdf

+ [ ] Create function sea_son() for calculating time of day (year) as fraction
The time of day can be used as an input into a seasonal model

+ [ ] Create volume-weighted Hurst and density plots  
https://quantivity.wordpress.com/2012/10/23/volume-clock-gaps-and-goog/

+ [ ] Modify function season_ality() to discard elements corresponding to infrequent observations ?

+ [ ] Create Rcpp function for fast rolling aggregations over endpoints

+ [ ] Aggregate data to 10-second bars (?)  

+ [ ] Add wiki  

+ [ ] Run on travis, add .travis.yml file, add Build Status tag to README.Rmd

+ [ ] Introduce unit testing using testthat and devtools: create /tests directory

+ [ ] Modify function skew_ohlc() to accomodate case when open price isn't equal to previous close price.  
add argument "open_to_close" with default value TRUE  

+ [ ] Prove that OHLC skew formula is an estimator of skew  
Do Garman-Klass and Rogers-Satchell estimators work for processes that are not Gaussian?  
perform simulation to find out  
https://en.wikipedia.org/wiki/First-hitting-time_model  
https://en.wikipedia.org/wiki/Wiener_process  

+ [ ] Add logical arg as option to aggregate data or not

+ [ ] Calculate rets from scrubbed data

+ [ ] Calculate statistics (moments, quantiles) on tick and OHLC data and save them in files

+ [ ] Create function to estimate beta from HFreq data

+ [ ] Create function to forecast skewness
Show that variance is predictable over time 
Show that skewness is not predictable over time (Harvey and Siddique, 1999), 
so variables other than lagged skewness are required to forecast skewness.
Show that idiosyncratic volatility is a strong predictor of idiosyncratic skewness.




### Tasks finished

+ [x] Replace the passing of large data by value with passing by reference (pointer) to improve performance (restore passing by reference which was removed)

+ [x] Add vignette and automatically build vignette  

+ [x] Create function roll_mean() for the rolling calc_mean() the centrality (location) estimator (first moment) using RcppArmadillo

+ [x] In functions roll_vec() and roll_vecw() convert arguments from arma::vec to arma::mat

+ [x] Modify function diff_it() to handle negative lags

+ [x] Modify function diff_it() to pad with zeros as in rutils::diff_it()

+ [x] In functions diff_vec() and diff_it(), rename argument padd to pad_zeros, as in lag_it()

+ [x] Modify function calc_inv() so it calculates the regularized inverse of a matrix, not the inverse of its covariance matrix

+ [x] Modify functions calc_reg() and roll_reg() to add method for regularized regression

+ [x] Create function calc_mean() for the centrality (location) estimator (first moment) using RcppArmadillo: mean, median, Hodges-Lehmann, and other unimodal robust estimators

+ [x] Create function roll_fun() to roll the functions calc_var(), calc_skew() and calc_kurtosis()

+ [x] Modify the functions which depend on calc_endpoints(): roll_reg(), roll_var(), roll_var_ohlc(), roll_skew(), roll_kurtosis(), roll_zscores()
Add arguments end_p and start_p and keep arguments step, stu_b, and look_back.
Add code to use end_p if it's non-zero, else to calculate end points from step, stu_b, and look_back.
Follow example of roll_wsum().

+ [x] Remove underscores from function arguments: rename stu_b to stub, oh_lc, weight_s, re_turns, se_ries, end_p, start_p

+ [x] In function calc_endpoints() add stub argument and remove argument front
The prototype is in test_temp.cpp

+ [x] Create function calc_reg() for performing different types of regressions
It should return a vector of coefficients, tvals, and zscore.
It's already partially implemented in C:/Develop/R/Rcpp/roll_reg.cpp

+ [x] Create function roll_reg() for performing rolling PCA and robust regressions
It should loop over end points using calc_endpoints() and calc_startpoints().
It should return a matrix of coefficients, tvals, and zscores.

+ [x] Update functions kurtosis_type() and calc_kurtosis() with actual kurtosis methods.

+ [x] Create function roll_kurtosis() for the rolling kurtosis estimator (fourth moment) using RcppArmadillo
It's already copied from C:/Develop/R/Rcpp/roll_kurtosis.cpp

+ [x] Create a function called roll_skew() for the rolling skewness estimator (third moment) using RcppArmadillo: include robust estimators
It's already implemented in C:/Develop/R/Rcpp/roll_skew.cpp

+ [x] In all the calc_* functions, return zero if number of rows is small

+ [x] Modify function roll_var() to calculate the rolling variance, MAD, and other robust estimators - add parameter "method" similar to calc_var() 

+ [x] Merge function calc_mad() into calc_var() - add parameter "method" to calc_var()

+ [x] In roll_wsum(), fix the naming conflict with the end_p argument, by declaring an internal Armadillo variable end_parma

+ [x] Fill new vectors and matrices with zeros using fill::zeros

+ [x] Rename parameter calc_method to method

+ [x] Create functions sim_ou() and sim_schwartz() to simulate the Ornstein-Uhlenbeck process and the Schwartz process.

+ [x] Rename argument t_series to se_ries

+ [x] Create function roll_sum() for calculating a simple rolling sum over the columns of a matrix, without weighting or end points

+ [x] Rename roll_sum() to roll_wsum()

+ [x] Modify functions back_test() and calc_weights(): rename argument typ_e to model_type

+ [x] Create functions calc_mad(), calc_skew(), and calc_skewnp() to calculate the Median Absolute Deviation, the skewness, and the nonparametric skewness
Calculate the nonparametric skewness estimator using the quantiles: skewness = (quartile_75 - median) - (median - quartile_25)

+ [x] Create a function called roll_count() using RcppArmadillo which reproduces roll_countr() in scratch.R
roll_count() is already in lm_arma.cpp.
roll_count() should count the number of consecutive TRUE elements, and reset to zero after every FALSE element.

+ [x] Rename roll_sum() to roll_vec(), and roll_wsum() to roll_vecw()

+ [x] Modify the old function roll_sum() so that it accepts matrix argument and calculates the rolling sum over the columns of a matrix
Modify function roll_sum() to use arma::cumsum() and diff_it(), instead of explicit loop.
Function roll_sum() aggregates returns to a lower periodicity, similar to roll_ohlc().
If weight_s argument is not NULL, then perform weighted sum using convolution and function arma::conv2().
It would then replicate functions roll_wsum(), roll_conv(), and roll_conv_ref().
Pass in parameters end_points and weight_s with default NULL values, using the syntax:
Rcpp::Nullable<Rcpp::IntegerVector> end_points = R_NilValue
https://stackoverflow.com/questions/34205925/default-null-parameter-rcpp

+ [x] Modify function diff_it() to pad with initial (warmup) period

+ [x] Modify functions lag_vec() and lag_it() to add parameter pad_zeros
Add Boolean argument pad_zeros with default TRUE.
Modify the padding of leading or trailing values in the functions lag_it() and lag_vec()
If pad_zeros is TRUE then pad the leading or trailing values with zeros, else pad with leading or trailing row.
The returns data should be padded with zeros, not the first or last element of the input vector.
The prices should be padded with the first or last element of the input vector, not with zeros.

+ [x] Rename the R function roll_moment() to roll_stats()

+ [x] Rename the R function agg_regate() to agg_stats_r(), and parameter mo_ment to calc_bars

+ [x] Add to file README.Rmd overview of function taxonomy
The functions run_* aggregate individual rows of TAQ or OHLC data into single numbers, and they transform multiple column of TAQ or OHLC data into column vectors
The functions calc_* aggregate columnar data into a single number.
The functions roll_* perform loops over the rows of columnar data, and they apply the functions calc_* to subsets of the data over look-back intervals.

+ [x] Modify the functions roll_var() and roll_var_ohlc() to perform calculations over end points if ste_p argument is passed in

+ [x] Modify the function agg_ohlc() so it can accept either one or two columns of data (second column for volume), or four or five columns of OHLC data

+ [x] Rename the function to_period() to roll_ohlc()

+ [x] Create function calc_startpoints() as a lag of end points (unsigned integers)

+ [x] Create a function called calc_endpoints() to calculate the end points, similar to rutils::calc_endpoints()

+ [x] Create the functions called agg_ohlc() and to_period() for aggregating an OHLC time series to lower periodicity, similar to xts::to.period()

+ [x] Modify the functions diff_it() and diff_vec() so they don't use arma::diff(), because it doesn't apply lags greater than one

+ [x] In function calc_weights() scale the weights so that the resulting portfolio has a volatility of 1% - make this a parameter

+ [x] In function calc_inv() add option to regularize the inverse by discarding small eigenvalues less than a tolerance level: use arma::pinv()
This is because the best choice for max_eigen can change in a rolling calculation, so it's better to introduce a tolerance cutoff.

+ [x] In function calc_weights() add option for quantile weights, with argument "typ_e == quantile" and add argument "quan_tile == 0.1": with weights equal to 1 for top quantile, -1 for bottom quantile, and otherwise 0.

+ [x] Change license from GPL to MPL, similar to package data.table.

+ [x] Rename roll_conv() to roll_conv_ref(), and modify roll_conv() so it doesn't copy over the input argument mat_rix.
Copying over the input argument mat_rix causes snooping data leak in backtest.

+ [x] Test the function roll_conv() to determine if it applies convolution only over past values.

+ [x] Rename function roll_wsum() to roll_conv(), because it replicates convolution - no!
The function roll_wsum() is for vectors and is not the same as roll_conv() which is for matrices.

+ [x] Create RcppArmadillo function calc_ranks() for calculating the ranks of the elements of a vector.

+ [x] Remove the existing function roll_variance() in R, and rewrite it in RcppArmadillo as roll_var()

+ [x] Compare the speed of performing RcppArmadillo loops over columns versus subviews of rows: loops over rows are slightly faster than over columns

+ [x] Create a function called roll_var_ohlc() in RcppArmadillo which calculates the rolling variance over a time series of OHLC prices

+ [x] Rename roll_var() to roll_var_vec() and update its documentation

+ [x] Create a function called roll_var() in RcppArmadillo which calculates the rolling dispersion estimator (variance - second moment) over a matrix using RcppArmadillo

+ [x] Create the functions called diff_vec() and diff_it() (for matrices), similar to rutils::diff_it(), using the RcppArmadillo function arma::diff()

+ [x] Create a function called calc_var_ohlc() in RcppArmadillo, which calculates the variance of a time series of OHLC prices, similar to the function calc_var_ohlc_r()

+ [x] Rename the existing R function calc_variance() to calc_var_ohlc_r(), and refactor the code to make it faster and more readable

+ [x] Create a function called lag_it() using RcppArmadillo which lags a column vector or a matrix, similar to rutils::lag_it()

+ [x] Create a function called lag_vec() using RcppArmadillo which lags a vector

+ [x] Create a function called calc_var() in RcppArmadillo to calculate the variance of a matrix

+ [x] Create a function called calc_var_vec() in RcppArmadillo to calculate the variance of a vector

+ [x] Add RcppArmadillo function mult_vec_mat(), which multiplies the columns or rows of a matrix times a vector, element-wise.

+ [x] In back_test() fix bid_offer bug: should be subtracted from PnL not added  

+ [x] In function calc_weights() add additional option for rank momentum, with argument "typ_e == rank": rank weights using trailing Sharpe

+ [x] In function back_test() add argument co_eff to multiply the weights.

+ [x] In function back_test() add transaction costs: remember previous weights and subtract current weights from previous weights
Add argument bid_offer the bid-offer spread.

+ [x] Rename function roll_portf() to back_test()

+ [x] Add header to HighFreq.R file to fix NAMESPACE issue:
#' @useDynLib HighFreq
#' @importFrom Rcpp evalCpp
#' @exportPattern "^[[:alpha:]]+"

+ [x] Create a function called roll_conv() for calculating the convolutions of the matrix columns

+ [x] In function calc_weights() add additional options for the typ_e argument: quadratic weights constraint (highest principal component)

+ [x] In function calc_weights() modify weight_s scaling: scale the weights to match the volatility of mean returns

+ [x] In function calc_weights() add argument called typ_e (with default value "max_sharpe"), which specifies the objective function of portfolio optimization used for calculating the weights

+ [x] Replace zoo::na.locf() with xts:::na.locf.xts()

+ [x] Remove RcppParallel dependency from DESCRIPTION

+ [x] Add ByteCompile: TRUE to the DESCRIPTION file

+ [x] Generate man files for Rcpp functions
Select the "Document" item in build menu or run R command devtools::document()

+ [x] Modify DESCRIPTION file
Added: Encoding: UTF-8
Removed from Imports: caTools, lubridate, TTR, 

+ [x] Fix build error about RcppExports.R.

+ [x] Modify functional roll_apply()
Change endpoints calculation: define look_backs as a list of numeric vectors.
Calculate aggregations using lapply() loop over the look_backs, instead of sapply().
Add option to coerce output into xts series.

+ [x] Create functional roll_backtest() similar to roll_apply(), but accepting two functions as arguments

+ [x] Replace argument "lag" with "lagg" (to avoid confusing it with stats function lag())  

+ [x] Replace calls to is.vector(in_put) with is.null(dim(in_put))

+ [x] Replace "win_dow" with "look_back"

+ [x] Fix bug in function run_variance() for calc_method="yang_zhang": remove win_dow from formula for co_eff.

+ [x] Replace xts::.subset_xts() with brackets operator []

+ [x] Add volatility, drift rate, and convexity correction to functions random_taq() and random_ohlc()  

+ [x] Fix bug in random_ohlc(): transform to normal distribution before sampling from rows of OHLC (otherwise it produces negative prices)  

+ [x] Move functions adjust_ohlc(), to_period() and get_symbols() from HighFreq to rutils  

+ [x] Remove and/or adjust time scaling factors in run_variance(), run_skew(), and random_ohlc()

+ [x] Rename functions *_OHLC and *_TAQ to *_ohlc and *_taq

+ [x] Create function adjust_ohlc() that adjusts OHLC data, similar to quantmod::adjustOHLC()  

+ [x] Create function get_symbols() that downloads time series data, similar to quantmod::getSymbols()  

+ [x] Replace quantmod extractor functions Op(), Hi(), Lo(), Cl(), Vo() with direct subsetting: oh_lc[, 3] Instead of Lo(oh_lc)

+ [x] Modify function run_returns(): add argument  

+ [x] Update README and web page  

+ [x] Add vignettes directory and create multiple vignettes using files README and demo_HighFreq.R  

+ [x] Create function random_TAQ() that returns random TAQ data

+ [x] Create function random_OHLC()
returns random OHLC data used for testing for data snooping (look ahead bias) and benchmarking
Either create synthetic data or sample from real data.  
Run random data through model to test if there is data snooping.  

+ [x] Add a single day of TAQ data for SPY to hf_data.RData file  

+ [x] Add TLT, VXX, and SPY to hf_data.RData file  

+ [x] Add lubridate to Imports in DESCRIPTION file  

+ [x] Create function roll_sharpe()

+ [x] Modify functions run_variance() and run_skew() to scale their outputs by the time differences, similar to run_returns()  

+ [x] Create a function called sim_arima() in RcppArmadillo which replicates the function stats::filter() with method="recursive"
Adapt code from C:/Develop/R/lecture_slides/scripts/sim_arima.cpp

+ [x] Add sim_* functions using RcppArmadillo: sim_arima(), sim_garch()

+ [x] Add calc_* functions using RcppArmadillo: calc_eigen(), calc_inv(), calc_scaled(), calc_lm(), calc_weights()

+ [x] Add roll_* functions using RcppArmadillo: roll_wsum(), roll_zscores(), roll_scale(), roll_portf()

+ [x] Create function remove_jumps() to remove overnight close-to-open jumps from OHLC (?)  

+ [x] Replace na.locf() with rutils::na_locf()

+ [x] Rename function extreme_values() to which_extreme()  

+ [x] Rename function price_jumps() to which_jumps()  

+ [x] Add arguments lag and sca_le to function run_returns()

+ [x] In functions calc_variance(), run_variance(), roll_variance(), and run_skew() don't perform log(oh_lc) - that can be done externally

+ [x] Replace calls to lag_xts() with lag_it()

+ [x] Replace calls to diff_xts() with diff_it()

+ [x] Add argument sca_le to functions run_variance() and roll_variance()

+ [x] Fix functions roll_hurst() and roll_sharpe() so they call roll_variance() instead of run_variance()  
in roll_hurst() replace TTR::runMax() with RcppRoll::roll_max()

+ [x] Remove arguments off_set and roll_end_points from function roll_hurst()

+ [x] Create function calc_variance() which calculates a single variance number from the output of run_variance()

+ [x] Create function roll_variance() that replicates TTR::volatility()  
Clone run_variance(), but modify it by subtracting the means
Use functions RcppRoll::roll_var() and rutils::roll_sum()
Add correct coefficient co_eff for yang_zhang method

+ [x] Modify comments for function run_variance() to explain that it's only an indicator, not an estimator

+ [x] Modify function run_returns(): remove time scaling, calculate percentage returns  

+ [x] Apply Hampel median filter to scrub data: that's what HighFreq does already  
http://dsp.stackexchange.com/questions/26552/what-is-a-hampel-filter-and-how-does-it-work
update the documentation to reflect that HighFreq already uses Hampel median filter

+ [x] Create functional roll_apply(), similar to xts:::rollapply.xts() and xts::period.apply()  
use apply_rolling() from utilLib

+ [x] Rename function roll_agg() to roll_moment(), and its argument esti_mator to mo_ment  

+ [x] Rename functions calc_returns(), vari_ance(), skew_ohlc(), sharpe_ohlc() to run_returns(), run_variance(), run_skew(), run_sharpe()  

+ [x] Rename function v_wap() to roll_vwap()  

+ [x] Modify function roll_hurst() using TTR::runMax()  

+ [x] Rename function hurst_ohlc() to sharpe_ohlc()  

+ [x] Rename and modify function calc_rets() to calc_returns(): 
return single column with name "SPY.returns"
will break save_rets() and save_rets_ohlc()

+ [x] Modify function v_wap() to accept argument x_ts  

+ [x] Remove .Rproj.user directory from GitHub repository
steps:
- open Windows PowerShell from GitHub Desktop
- run: git filter-branch --tree-filter 'rm -f -R .Rproj.user' HEAD
- run: git push origin master -f
http://stackoverflow.com/questions/32228841/github-gitignore-adds-folder-previously-not-on-gitignore

+ [x] Create project website for HighFreq on GitHub Pages using R Markdown  

+ [x] Rename README.md to .Rmd and add more detailed description similar this to README.md:  
https://github.com/RcppCore/rcpp-gallery/blob/gh-pages/src/2016-05-27-HRP.Rmd
use rmarkdown templates
https://rud.is/b/2016/02/04/alternate-r-markdown-templates/
https://github.com/hrbrmstr/markdowntemplates
http://svmiller.com/blog/2016/02/svm-r-markdown-manuscript/

+ [x] Modify function hurst_ohlc() to calculate (C-O)/(H-L)

+ [x] Create function roll_hurst() for rolling Hurst exponent, similar to roll_sum()  
Detrended fluctuation analysis - is it like variance ratios?
Hurst analysis is related to Detrended fluctuation analysis:
https://en.wikipedia.org/wiki/Detrended_fluctuation_analysis
HurstIndex() from PerformanceAnalytics is wrong because it uses range of returns, instead of range of cumulative returns!
variance ratio test
http://quant.stackexchange.com/questions/7666/using-variance-ratios-to-test-for-mean-reversion

+ [x] Move function roll_sum() from HighFreq to rutils

+ [x] Add to function season_ality() in_dex argument

+ [x] Perform bootstrap estimation of standard errors for all the methods in function vari_ance()  
benchmark to random OHLC

+ [x] Add to function vari_ance() the methods "garman.klass_yz" and "yang.zhang"  

+ [x] Modify functions vari_ance() to accomodate case when open price isn't equal to previous close price - methods "garman.klass_yz" and "yang.zhang"  

+ [x] Rename function vol_ohlc() to vari_ance()

+ [x] Create function to_period()  

+ [x] Rename argument agg_fun to esti_mator, in functions agg_regate() and roll_agg()  

+ [x] Remove calc_method argument from agg_regate() and roll_agg() - instead use "..." argument

+ [x] Rename agg_ohlc and roll_agg_ohlc() to agg_regate() and roll_agg()  

+ [x] Dereference all external functions using "::", i.e. rutils::na_me()

+ [x] Add @export to roxygen code  

+ [x] Convert all code from nrow() and ncol() to NROW() and NCOL()  

+ [x] Replace strsplit(colnames(ohlc)[1], split="[.]")[[1]][1] With rutils::na_me(ohlc)  

+ [x] Fix roxygen .Rd documentation file building error - name at end of hf_data.R file was wrong - should be the names of objects, i.e. "SPY", "sym_bol", not the file name  

+ [x] Create data documention  

+ [x] Rename moment_ohlc() and roll_moment_ohlc() to agg_ohlc and roll_agg_ohlc()
mom_fun to agg_fun

+ [x] Create function hurst_ohlc() for calculating Hurst exponent from OHLC data
OHLC data naturally lends itself to Hurst analysis: ratio of (H-L)/(C-O)

+ [x] In moment_ohlc() and roll_moment_ohlc() removed log of ohlc
moment_ohlc() and roll_moment_ohlc() should pass ohlc to skew_ohlc() and vol_ohlc(), etc., not log ohlc

+ [x] Modify skew_ohlc() and vol_ohlc() to accept ohlc, not log ohlc, and to apply log internally

+ [x] Include rutil package 

+ [x] Create function for performing daily, weekly, and monthly seasonality aggregations

+ [x] Rename functions run_* to roll_*

+ [x] Rename save_OHLC() to save_scrub_agg()

+ [x] In save_rets_OHLC() update documentation

+ [x] In save_OHLC() combine sapply loops into one

+ [x] In save_OHLC() and save_rets() pass scrub params to scrub_agg

+ [x] Add timezone to argument list

+ [x] Create function save_TAQ()
	saves scrubbed TAQ and/or OHLC data in daily files
	similar to save_OHLC, but doesn't aggregate and saves into multiple files

+ [x] Create function calc_rets()
	calculate returns of time series

created function save_rets() (similar to save_OHLC): 
	scrub and aggregate data, calculate returns, and save them

created function save_rets_OHLC()
	similar to save_rets, but assumes clean OHLC input data
	- no scrubbing or aggregation


### Tasks deprecated

+ [ ] Remove unnecessary pointer "&" and "const" attributes from input arguments - No!
Passing pointers as arguments into functions increases their speed by 30% or more for very large vectors with a million or more elements.

+ [ ] In function roll_wsum() add argument start_p - it's not needed because the length of weights determines the start points

+ [ ] Rename the function roll_zscores() to roll_reg()

+ [ ] Rewrite the function roll_zscores() to make it similar to roll_var(): create function calc_zscores() and loop over end points using calc_endpoints() and calc_startpoints()

+ [ ] Create a function called roll_stdev() for the rolling standard deviation, MAD, and other unimodal robust estimators

+ [ ] Convert roll_* functions to RcppRoll ?  No, because RcppArmadillo and Rcpp are better

+ [ ] Rename the functions run_* to to cast_* apply_* transform_* accumulate_*?

+ [ ] Modify function run_returns() to perform sapply() if argument has multiple columns ?

+ [ ] Remove extra increment of 1 in start_points index in roll_apply() - no, because otherwise it would create overlaps when aggregating returns (for example)  
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))]
instead of:
start_points <-  end_points[c(rep_len(1, win_dow-1), 1:(len_gth-win_dow+1))] + (NROW(oh_lc) > (len_gth+1))

+ [ ] Modify "close" method in function run_variance() by averaging open and close prices - no creates a bias underestimates variance  

+ [ ] Subtract mean in functions run_variance() and run_skew() - no  

+ [ ] Convert function season_ality() to use split.xts() (?)  

+ [ ] Replace caTools with TTR functions (?)  
only runquantile() is called from caTools  
but not easy to replace runquantile(), because no equivalent TTR function  
would require rewriting extreme_values() and price_jumps(), and then benchmarking  

+ [ ] Use .subset_xts() (?)

+ [ ] Rename save_rets_OHLC to rets_OHLC (?)  

+ [ ] Calculate volume-weighted moments and compare them to standard moments
add volume-weighting to vol_ohlc() and skew_ohlc()


### Commits

# commit 05-18-16
added rutils to depends in DESCRIPTION
moved do_call_rbind to rutils

# commit 05-17-16 bis
Added function season_ality()

# commit 05-17-16
Renamed functions from run_* to roll_*

# commit 11-03-15
fixed function v_wap() from Ad() to Cl()

# commit 10-03-15
added functions run_sum() and v_wap()

# commit 05-29-15
Finished R/Finance_2015 presentation

# commit 03-27-15
added timezone to argument list
updated functions: calc_rets, save_rets

# commit 03-16-15
added functions: calc_rets, save_rets, save_TAQ
updated functions: save_OHLC, scrub_TAQ
added "data" folder
updated roxygen documentation


# commit 03-01-15
added roxygen documentation

created functions:
save_OHLC
scrub_TAQ

scrub_agg:
change time zone
to trading hours
merge duplicate time stamps using make.index.unique - no
remove duplicate time stamps using duplicated
calculate mid price?
NA omit mid price
convert NA volumes to zero
replace NA trade prices with mid prices
scrub on mid price:
	bid-offer spread
	if bid-offer spread too wide then use trade price?
	hairlines


in save_OHLC
add save dir
coerce using quantmod.OHLC? - no

create function save_TAQ:
save scrubbed daily TAQ data to daily files
use quantmod standard headers - quantmod naming conventions

create function similar to getSymbols (?):
load and rbind TAQ data (without scrubbing or aggregating)


# commit 02-17-15
renamed many functions and variables
added roxygen comments
added demo folder and files
edited README
updated HighFreq-package.Rd



